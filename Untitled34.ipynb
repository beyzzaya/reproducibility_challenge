{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beyzzaya/reproducibility_challenge/blob/main/Untitled34.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Gf8vuxShbeB"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/PIQ2023/src/models/archs')\n",
        "\n",
        "# Now you can import your modules without import errors\n",
        "from sem_hyperiqa_util import HyperNet, RescaleNet, TargetNet, SceneClassNet\n",
        "from arch_util import load_file_from_url"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "MfOYvDf2hL_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeTWGgfDtH_j",
        "outputId": "8301fe09-160b-4911-b559-ab7c2457dbaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PIQ2023'...\n",
            "remote: Enumerating objects: 321, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 321 (delta 18), reused 36 (delta 13), pack-reused 278\u001b[K\n",
            "Receiving objects: 100% (321/321), 21.34 MiB | 22.76 MiB/s, done.\n",
            "Resolving deltas: 100% (121/121), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/DXOMARK-Research/PIQ2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1251pktti9s",
        "outputId": "d91964ce-3de3-4c49-c245-1beaf0d4705f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6FuL0aay9sM"
      },
      "outputs": [],
      "source": [
        "!python /content/PIQ2023/src/models/archs/arch_util.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFCdi2s70X3C"
      },
      "outputs": [],
      "source": [
        "!python PIQ2023/src/models/archs/sem_hyperiqa_util.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQEt8Yek3Gpp"
      },
      "outputs": [],
      "source": [
        "!python /content/PIQ2023/src/models/archs/sem_hyperiqa_arch.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oLkTalR8Mhs"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import collections.abc\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from typing import Tuple\n",
        "from urllib.parse import urlparse\n",
        "from itertools import repeat\n",
        "from torch import nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.nn import init as init\n",
        "from torch.nn.modules.batchnorm import _BatchNorm\n",
        "from torch.hub import download_url_to_file, get_dir\n",
        "\n",
        "\n",
        "# --------------------------------------------\n",
        "# IQA utils\n",
        "    # Code taken from: https://github.com/chaofengc/IQA-PyTorch\n",
        "# --------------------------------------------\n",
        "\n",
        "def load_file_from_url(url, model_dir=None, progress=True, file_name=None):\n",
        "    \"\"\"Load file form http url, will download models if necessary.\n",
        "\n",
        "    Ref: https://github.com/1adrianb/face-alignment/blob/master/face_alignment/utils.py\n",
        "\n",
        "    Args:\n",
        "        url (str): URL to be downloaded.\n",
        "        model_dir (str): The path to save the downloaded model. Should be a full path. If None, use pytorch hub_dir.\n",
        "            Default: None.\n",
        "        progress (bool): Whether to show the download progress. Default: True.\n",
        "        file_name (str): The downloaded file name. If None, use the file name in the url. Default: None.\n",
        "\n",
        "    Returns:\n",
        "        str: The path to the downloaded file.\n",
        "    \"\"\"\n",
        "    if model_dir is None:  # use the pytorch hub_dir\n",
        "        hub_dir = get_dir()\n",
        "        model_dir = os.path.join(hub_dir, 'checkpoints')\n",
        "\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    parts = urlparse(url)\n",
        "    filename = os.path.basename(parts.path)\n",
        "    if file_name is not None:\n",
        "        filename = file_name\n",
        "    cached_file = os.path.abspath(os.path.join(model_dir, filename))\n",
        "    if not os.path.exists(cached_file):\n",
        "        print(f'Downloading: \"{url}\" to {cached_file}\\n')\n",
        "        download_url_to_file(url, cached_file, hash_prefix=None, progress=progress)\n",
        "    return cached_file\n",
        "\n",
        "def dist_to_mos(dist_score: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Convert distribution prediction to mos score.\n",
        "    For datasets with detailed score labels, such as AVA\n",
        "\n",
        "    Args:\n",
        "        dist_score (tensor): (*, C), C is the class number\n",
        "\n",
        "    Output:\n",
        "        mos_score (tensor): (*, 1)\n",
        "    \"\"\"\n",
        "    num_classes = dist_score.shape[-1]\n",
        "    mos_score = dist_score * torch.arange(1, num_classes + 1).to(dist_score)\n",
        "    mos_score = mos_score.sum(dim=-1, keepdim=True)\n",
        "    return mos_score\n",
        "\n",
        "\n",
        "# --------------------------------------------\n",
        "# Common utils\n",
        "# --------------------------------------------\n",
        "\n",
        "\n",
        "def load_pretrained_network(net, model_path, strict=True, weight_keys=None):\n",
        "    if model_path.startswith('https://') or model_path.startswith('http://'):\n",
        "        model_path = load_file_from_url(model_path)\n",
        "    print(f'Loading pretrained model {net.__class__.__name__} from {model_path}')\n",
        "    state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "    if weight_keys:\n",
        "        state_dict = state_dict[weight_keys]\n",
        "    net.load_state_dict(state_dict, strict=strict)\n",
        "\n",
        "\n",
        "def _ntuple(n):\n",
        "\n",
        "    def parse(x):\n",
        "        if isinstance(x, collections.abc.Iterable):\n",
        "            return x\n",
        "        return tuple(repeat(x, n))\n",
        "\n",
        "    return parse\n",
        "\n",
        "\n",
        "to_1tuple = _ntuple(1)\n",
        "to_2tuple = _ntuple(2)\n",
        "to_3tuple = _ntuple(3)\n",
        "to_4tuple = _ntuple(4)\n",
        "to_ntuple = _ntuple\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def default_init_weights(module_list, scale=1, bias_fill=0, **kwargs):\n",
        "    r\"\"\"Initialize network weights.\n",
        "\n",
        "    Args:\n",
        "        module_list (list[nn.Module] | nn.Module): Modules to be initialized.\n",
        "        scale (float): Scale initialized weights, especially for residual\n",
        "            blocks. Default: 1.\n",
        "        bias_fill (float): The value to fill bias. Default: 0.\n",
        "        kwargs (dict): Other arguments for initialization function.\n",
        "\n",
        "    \"\"\"\n",
        "    if not isinstance(module_list, list):\n",
        "        module_list = [module_list]\n",
        "    for module in module_list:\n",
        "        for m in module.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                init.kaiming_normal_(m.weight, **kwargs)\n",
        "                m.weight.data *= scale\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.fill_(bias_fill)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                init.kaiming_normal_(m.weight, **kwargs)\n",
        "                m.weight.data *= scale\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.fill_(bias_fill)\n",
        "            elif isinstance(m, _BatchNorm):\n",
        "                init.constant_(m.weight, 1)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.fill_(bias_fill)\n",
        "\n",
        "\n",
        "def symm_pad(im: torch.Tensor, padding: Tuple[int, int, int, int]):\n",
        "    \"\"\"Symmetric padding same as tensorflow.\n",
        "    Ref: https://discuss.pytorch.org/t/symmetric-padding/19866/3\n",
        "    \"\"\"\n",
        "    h, w = im.shape[-2:]\n",
        "    left, right, top, bottom = padding\n",
        "\n",
        "    x_idx = np.arange(-left, w+right)\n",
        "    y_idx = np.arange(-top, h+bottom)\n",
        "\n",
        "    def reflect(x, minx, maxx):\n",
        "        \"\"\" Reflects an array around two points making a triangular waveform that ramps up\n",
        "        and down,  allowing for pad lengths greater than the input length \"\"\"\n",
        "        rng = maxx - minx\n",
        "        double_rng = 2*rng\n",
        "        mod = np.fmod(x - minx, double_rng)\n",
        "        normed_mod = np.where(mod < 0, mod+double_rng, mod)\n",
        "        out = np.where(normed_mod >= rng, double_rng - normed_mod, normed_mod) + minx\n",
        "        return np.array(out, dtype=x.dtype)\n",
        "\n",
        "    x_pad = reflect(x_idx, -0.5, w-0.5)\n",
        "    y_pad = reflect(y_idx, -0.5, h-0.5)\n",
        "    xx, yy = np.meshgrid(x_pad, y_pad)\n",
        "    return im[..., yy, xx]\n",
        "\n",
        "\n",
        "def exact_padding_2d(x, kernel, stride=1, dilation=1, mode='same'):\n",
        "    assert len(x.shape) == 4, f'Only support 4D tensor input, but got {x.shape}'\n",
        "    kernel = to_2tuple(kernel)\n",
        "    stride = to_2tuple(stride)\n",
        "    dilation = to_2tuple(dilation)\n",
        "    b, c, h, w = x.shape\n",
        "    h2 = math.ceil(h / stride[0])\n",
        "    w2 = math.ceil(w / stride[1])\n",
        "    pad_row = (h2 - 1) * stride[0] + (kernel[0] - 1) * dilation[0] + 1 - h\n",
        "    pad_col = (w2 - 1) * stride[1] + (kernel[1] - 1) * dilation[1] + 1 - w\n",
        "    pad_l, pad_r, pad_t, pad_b = (pad_col // 2, pad_col - pad_col // 2, pad_row // 2, pad_row - pad_row // 2)\n",
        "\n",
        "    mode = mode if mode != 'same' else 'constant'\n",
        "    if mode != 'symmetric':\n",
        "        x = F.pad(x, (pad_l, pad_r, pad_t, pad_b), mode=mode)\n",
        "    elif mode == 'symmetric':\n",
        "        x = symm_pad(x, (pad_l, pad_r, pad_t, pad_b))\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "class ExactPadding2d(nn.Module):\n",
        "    r\"\"\"This function calculate exact padding values for 4D tensor inputs,\n",
        "    and support the same padding mode as tensorflow.\n",
        "\n",
        "    Args:\n",
        "        kernel (int or tuple): kernel size.\n",
        "        stride (int or tuple): stride size.\n",
        "        dilation (int or tuple): dilation size, default with 1.\n",
        "        mode (srt): padding mode can be ('same', 'symmetric', 'replicate', 'circular')\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, kernel, stride=1, dilation=1, mode='same'):\n",
        "        super().__init__()\n",
        "        self.kernel = to_2tuple(kernel)\n",
        "        self.stride = to_2tuple(stride)\n",
        "        self.dilation = to_2tuple(dilation)\n",
        "        self.mode = mode\n",
        "\n",
        "    def forward(self, x):\n",
        "        return exact_padding_2d(x, self.kernel, self.stride, self.dilation, self.mode)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHiUGf1tsvvs"
      },
      "outputs": [],
      "source": [
        "import torch as torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.nn import init\n",
        "import math\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class HyperNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Hyper network for learning perceptual rules.\n",
        "    # Code adapted from: https://github.com/SSL92/hyperIQA\n",
        "\n",
        "    Args:\n",
        "        lda_out_channels: local distortion aware module output size.\n",
        "        hyper_in_channels: input feature channels for hyper network.\n",
        "        target_in_size: input vector size for target network.\n",
        "        target_fc(i)_size: fully connection layer size of target network.\n",
        "        feature_size: input feature map width/height for hyper network.\n",
        "\n",
        "    Note:\n",
        "        For size match, input args must satisfy: 'target_fc(i)_size * target_fc(i+1)_size' is divisible by 'feature_size ^ 2'.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, lda_out_channels, hyper_in_channels, target_in_size, target_fc1_size, target_fc2_size, target_fc3_size, target_fc4_size, feature_size, patch_rate, **kwargs):\n",
        "        super(HyperNet, self).__init__()\n",
        "        self.hyperInChn = hyper_in_channels\n",
        "        self.target_in_size = target_in_size\n",
        "        self.f1 = target_fc1_size\n",
        "        self.f2 = target_fc2_size\n",
        "        self.f3 = target_fc3_size\n",
        "        self.f4 = target_fc4_size\n",
        "        self.feature_size = feature_size\n",
        "        self.patch_rate = patch_rate\n",
        "\n",
        "        self.res = resnet50_backbone(lda_out_channels, target_in_size, patch_rate=self.patch_rate, pretrained=True)\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.poolClass = None\n",
        "        if kwargs.get('classFeaturesOut', None) is not None:\n",
        "            self.poolClass = nn.AdaptiveAvgPool2d((1, kwargs.get('classFeaturesOut')))\n",
        "\n",
        "        # Conv layers for resnet output features\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(2048, 1024, 1, padding=(0, 0)),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(1024, 512, 1, padding=(0, 0)),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, self.hyperInChn, 1, padding=(0, 0)),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Hyper network part, conv for generating target fc weights, fc for generating target fc biases\n",
        "        self.fc1w_conv = nn.Conv2d(self.hyperInChn, int(self.target_in_size * self.f1 / feature_size ** 2), 3,  padding=(1, 1))\n",
        "        self.fc1b_fc = nn.Linear(self.hyperInChn, self.f1)\n",
        "\n",
        "        self.fc2w_conv = nn.Conv2d(self.hyperInChn, int(self.f1 * self.f2 / feature_size ** 2), 3, padding=(1, 1))\n",
        "        self.fc2b_fc = nn.Linear(self.hyperInChn, self.f2)\n",
        "\n",
        "        self.fc3w_conv = nn.Conv2d(self.hyperInChn, int(self.f2 * self.f3 / feature_size ** 2), 3, padding=(1, 1))\n",
        "        self.fc3b_fc = nn.Linear(self.hyperInChn, self.f3)\n",
        "\n",
        "        self.fc4w_conv = nn.Conv2d(self.hyperInChn, int(self.f3 * self.f4 / feature_size ** 2), 3, padding=(1, 1))\n",
        "        self.fc4b_fc = nn.Linear(self.hyperInChn, self.f4)\n",
        "\n",
        "        self.fc5w_fc = nn.Linear(self.hyperInChn, self.f4)\n",
        "        self.fc5b_fc = nn.Linear(self.hyperInChn, 1)\n",
        "\n",
        "        # initialize\n",
        "        for i, m_name in enumerate(self._modules):\n",
        "            if i > 3:\n",
        "                nn.init.kaiming_normal_(self._modules[m_name].weight.data)\n",
        "\n",
        "    def _forward(self, imgTensorIn):\n",
        "        feature_size = self.feature_size\n",
        "        res_out = self.res(imgTensorIn)\n",
        "\n",
        "        # input vector for target net\n",
        "        target_in_vec = res_out['target_in_vec'].view(-1, self.target_in_size, 1, 1)\n",
        "\n",
        "        # input features for hyper net\n",
        "        hyper_in_feat = self.conv1(res_out['hyper_in_feat']).view(-1, self.hyperInChn, feature_size, feature_size)\n",
        "\n",
        "        # generating target net weights & biases\n",
        "        target_fc1w = self.fc1w_conv(hyper_in_feat).view(-1, self.f1, self.target_in_size, 1, 1)\n",
        "        target_fc1b = self.fc1b_fc(self.pool(hyper_in_feat).squeeze()).view(-1, self.f1)\n",
        "\n",
        "        target_fc2w = self.fc2w_conv(hyper_in_feat).view(-1, self.f2, self.f1, 1, 1)\n",
        "        target_fc2b = self.fc2b_fc(self.pool(hyper_in_feat).squeeze()).view(-1, self.f2)\n",
        "\n",
        "        target_fc3w = self.fc3w_conv(hyper_in_feat).view(-1, self.f3, self.f2, 1, 1)\n",
        "        target_fc3b = self.fc3b_fc(self.pool(hyper_in_feat).squeeze()).view(-1, self.f3)\n",
        "\n",
        "        target_fc4w = self.fc4w_conv(hyper_in_feat).view(-1, self.f4, self.f3, 1, 1)\n",
        "        target_fc4b = self.fc4b_fc(self.pool(hyper_in_feat).squeeze()).view(-1, self.f4)\n",
        "\n",
        "        target_fc5w = self.fc5w_fc(self.pool(hyper_in_feat).squeeze()).view(-1, 1, self.f4, 1, 1)\n",
        "        target_fc5b = self.fc5b_fc(self.pool(hyper_in_feat).squeeze()).view(-1, 1)\n",
        "\n",
        "        out = {}\n",
        "        out['target_in_vec'] = target_in_vec\n",
        "        out['target_fc1w'] = target_fc1w\n",
        "        out['target_fc1b'] = target_fc1b\n",
        "        out['target_fc2w'] = target_fc2w\n",
        "        out['target_fc2b'] = target_fc2b\n",
        "        out['target_fc3w'] = target_fc3w\n",
        "        out['target_fc3b'] = target_fc3b\n",
        "        out['target_fc4w'] = target_fc4w\n",
        "        out['target_fc4b'] = target_fc4b\n",
        "        out['target_fc5w'] = target_fc5w\n",
        "        out['target_fc5b'] = target_fc5b\n",
        "\n",
        "        if self.poolClass:\n",
        "            return out, torch.flatten(self.poolClass(hyper_in_feat), 1)\n",
        "        return out\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        if isinstance(input, list):\n",
        "            # Ideally this should not be used, since the input should be a tensor of concatenated inputs not a list of inputs.\n",
        "            out_all = []\n",
        "            hyper_in_all = []\n",
        "            for elt in input:\n",
        "                # this elt in img is considering img to be a list of patches so a list of [torch.Size([batch_size, 3, patch_size, patch_size])]\n",
        "                out = self._forward(elt)\n",
        "                if self.poolClass:\n",
        "                    out_all.append(out[0])\n",
        "                    hyper_in_all.append(out[1])\n",
        "                else:\n",
        "                    out_all.append(out)\n",
        "            if self.poolClass:\n",
        "                return out_all, hyper_in_all\n",
        "            return out_all\n",
        "\n",
        "        return self._forward(input)\n",
        "\n",
        "\n",
        "\n",
        "class TargetNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Target network for quality prediction.\n",
        "    \"\"\"\n",
        "    def __init__(self, paras):\n",
        "        super(TargetNet, self).__init__()\n",
        "        self.l1 = nn.Sequential(\n",
        "            TargetFC(paras['target_fc1w'], paras['target_fc1b']),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.l2 = nn.Sequential(\n",
        "            TargetFC(paras['target_fc2w'], paras['target_fc2b']),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "        self.l3 = nn.Sequential(\n",
        "            TargetFC(paras['target_fc3w'], paras['target_fc3b']),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "        self.l4 = nn.Sequential(\n",
        "            TargetFC(paras['target_fc4w'], paras['target_fc4b']),\n",
        "            nn.Sigmoid(),\n",
        "            TargetFC(paras['target_fc5w'], paras['target_fc5b']),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        q = self.l1(x)\n",
        "\n",
        "        q = self.l2(q)\n",
        "        q = self.l3(q)\n",
        "        q = self.l4(q).squeeze()\n",
        "\n",
        "        return q\n",
        "\n",
        "\n",
        "class TargetFC(nn.Module):\n",
        "    \"\"\"\n",
        "    Fully connection operations for target net\n",
        "    \"\"\"\n",
        "    def __init__(self, weight, bias):\n",
        "        super(TargetFC, self).__init__()\n",
        "        self.weight = weight\n",
        "        self.bias = bias\n",
        "\n",
        "    def forward(self, input_):\n",
        "        input_re = input_.view(-1, input_.shape[0] * input_.shape[1], input_.shape[2], input_.shape[3])\n",
        "        weight_re = self.weight.view(self.weight.shape[0] * self.weight.shape[1], self.weight.shape[2], self.weight.shape[3], self.weight.shape[4])\n",
        "        bias_re = self.bias.view(self.bias.shape[0] * self.bias.shape[1])\n",
        "\n",
        "        out = F.conv2d(input=input_re, weight=weight_re, bias=bias_re, groups=self.weight.shape[0])\n",
        "\n",
        "        return out.view(input_.shape[0], self.weight.shape[1], input_.shape[2], input_.shape[3])\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNetBackbone(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNet50 backbone model for feature extraction\n",
        "    Outputs:\n",
        "        out : dictionnary containing the input features of the hypernetwork and target features for FC-quality\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, lda_out_channels, in_chn, block, layers, patch_rate, num_classes=1000):\n",
        "        super(ResNetBackbone, self).__init__()\n",
        "        self.inplanes = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "        # local distortion aware module\n",
        "        self.lda1_pool = nn.Sequential(\n",
        "            nn.Conv2d(256, 16, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.AvgPool2d(7, stride=7),\n",
        "\n",
        "        )\n",
        "        self.lda1_fc = nn.Linear(16 * 64 * patch_rate * patch_rate , lda_out_channels)\n",
        "\n",
        "        self.lda2_pool = nn.Sequential(\n",
        "            nn.Conv2d(512, 32, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.AvgPool2d(7, stride=7),\n",
        "        )\n",
        "        self.lda2_fc = nn.Linear(32 * 16 * patch_rate * patch_rate, lda_out_channels)\n",
        "\n",
        "        self.lda3_pool = nn.Sequential(\n",
        "            nn.Conv2d(1024, 64, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.AvgPool2d(7, stride=7),\n",
        "        )\n",
        "        self.lda3_fc = nn.Linear(64 * 4 * patch_rate * patch_rate, lda_out_channels)\n",
        "\n",
        "        self.lda4_pool = nn.AvgPool2d(7, stride=7)\n",
        "        self.lda4_fc = nn.Linear(2048 * patch_rate * patch_rate, in_chn - lda_out_channels * 3)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "        # initialize\n",
        "        nn.init.kaiming_normal_(self.lda1_pool._modules['0'].weight.data)\n",
        "        nn.init.kaiming_normal_(self.lda2_pool._modules['0'].weight.data)\n",
        "        nn.init.kaiming_normal_(self.lda3_pool._modules['0'].weight.data)\n",
        "        nn.init.kaiming_normal_(self.lda1_fc.weight.data)\n",
        "        nn.init.kaiming_normal_(self.lda2_fc.weight.data)\n",
        "        nn.init.kaiming_normal_(self.lda3_fc.weight.data)\n",
        "        nn.init.kaiming_normal_(self.lda4_fc.weight.data)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "\n",
        "        # the same effect as lda operation in the paper, but save much more memory\n",
        "        lda_1 = self.lda1_fc(self.lda1_pool(x).view(x.size(0), -1))\n",
        "        x = self.layer2(x)\n",
        "        lda_2 = self.lda2_fc(self.lda2_pool(x).view(x.size(0), -1))\n",
        "        x = self.layer3(x)\n",
        "        lda_3 = self.lda3_fc(self.lda3_pool(x).view(x.size(0), -1))\n",
        "        x = self.layer4(x)\n",
        "        lda_4 = self.lda4_fc(self.lda4_pool(x).view(x.size(0), -1))\n",
        "\n",
        "        vec = torch.cat((lda_1, lda_2, lda_3, lda_4), 1)\n",
        "\n",
        "        out = {}\n",
        "        out['hyper_in_feat'] = x\n",
        "        out['target_in_vec'] = vec\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "def resnet50_backbone(lda_out_channels, in_chn, patch_rate, pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-50 model_hyper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model_hyper pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNetBackbone(lda_out_channels, in_chn, Bottleneck, [3, 4, 6, 3], patch_rate, **kwargs)\n",
        "    if pretrained:\n",
        "        save_model = torch.load(load_file_from_url(model_urls['resnet50']))\n",
        "        model_dict = model.state_dict()\n",
        "        state_dict = {k: v for k, v in save_model.items() if k in model_dict.keys()}\n",
        "        model_dict.update(state_dict)\n",
        "        model.load_state_dict(model_dict)\n",
        "    else:\n",
        "        model.apply(weights_init_xavier)\n",
        "\n",
        "    return model\n",
        "\n",
        "def weights_init_xavier(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        init.kaiming_normal_(m.weight.data)\n",
        "        init.constant_(m.bias.data, 0.0)\n",
        "    elif classname.find('Linear') != -1:\n",
        "        init.kaiming_normal_(m.weight.data)\n",
        "        init.constant_(m.bias.data, 0.0)\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "        init.uniform_(m.weight.data, 1.0, 0.02)\n",
        "        init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "\n",
        "### FULLY-CONNECTED PART FOR SCENE CLASSIFICATION ###\n",
        "class SceneClassNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Fully-connected network for scene type classification.\n",
        "    Input :\n",
        "        hyperInFeat (feature vector outputed by Hypernetwork). size=torch.Size([batchSize, patchSize // 2, 7, 7])\n",
        "    Output :\n",
        "        scene type vector. type=torch.tensor([batchSize, numClasses])\n",
        "    \"\"\"\n",
        "    def __init__(self, featureInSize, numClasses, numLayers=3, numIntermediateNodes=500, **kwargs):\n",
        "        super(SceneClassNet, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        # Input layer\n",
        "        self.layers.append(nn.Linear(featureInSize, numIntermediateNodes))\n",
        "        self.layers.append(nn.ReLU())\n",
        "\n",
        "        # Intermediate layers\n",
        "        for _ in range(numLayers - 2):  # subtract 2 because we already have the input layer and will add the output layer\n",
        "            self.layers.append(nn.Linear(numIntermediateNodes, numIntermediateNodes))\n",
        "            self.layers.append(nn.ReLU())\n",
        "\n",
        "        # Output layer\n",
        "        self.layers.append(nn.Linear(numIntermediateNodes, numClasses))\n",
        "\n",
        "        # Apply custom weights initialization\n",
        "        self.apply(weights_init_xavier)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "### FULLY-CONNECTED PART FOR SCENE CLASSIFICATION ###\n",
        "#class SceneClassNet(nn.Module):\n",
        "class RescaleNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Target network for scene type classification.\n",
        "    Input : hyperInFeat (feature vector outputted by Hypernetwork). size=torch.Size([batchSize, patchSize // 2, 7, 7])\n",
        "    Output : scene type vector. type=torch.tensor([batchSize, 20])\n",
        "    \"\"\"\n",
        "    def __init__(self, featureInSize, numLayers=3, numIntermediateNodes=100, polyDegree=2, **kwargs):\n",
        "        super(RescaleNet, self).__init__()\n",
        "        self.numLayers = numLayers\n",
        "        self.numIntermediateNodes = numIntermediateNodes\n",
        "        self.polyDegree = polyDegree\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        # Input layer\n",
        "        self.layers.append(nn.Linear(featureInSize, self.numIntermediateNodes))\n",
        "        self.layers.append(nn.ReLU())\n",
        "\n",
        "        # Intermediate layers\n",
        "        for _ in range(self.numLayers - 1):\n",
        "            self.layers.append(nn.Linear(self.numIntermediateNodes, self.numIntermediateNodes))\n",
        "            self.layers.append(nn.ReLU())\n",
        "\n",
        "        # Output layer\n",
        "        self.layers.append(nn.Linear(self.numIntermediateNodes, self.polyDegree))\n",
        "\n",
        "        # Apply custom weights initialization\n",
        "        self.apply(weights_init_xavier)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DMcciSjtBlH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import one_hot\n",
        "\n",
        "\n",
        "defaultHyperNetWeights = {\n",
        "    # Only for original hyperIQA model with input size 224x224\n",
        "    'koniq': None #link: https://drive.google.com/file/d/1OOUmnbvpGea0LIGpIWEbOyxfWx6UCiiE/view\n",
        "}\n",
        "\n",
        "defaultWeights = {}\n",
        "\n",
        "\n",
        "class SemHyperIQA(nn.Module):\n",
        "    def __init__(self, patchSize,\n",
        "                 hyperNetPretrained=None,\n",
        "                 pretrained=None,\n",
        "                 classify=None,\n",
        "                 rescale=None,\n",
        "                  **kwargs):\n",
        "\n",
        "        super().__init__()\n",
        "        patchRate = patchSize // 224\n",
        "        self.classify = classify\n",
        "        self.rescale = rescale\n",
        "        self.classFeaturesOut = None\n",
        "        self.nbPatchesIn = None\n",
        "        self.classKey = kwargs.get('classKey', 'class')\n",
        "        self.qualityKey = kwargs.get('qualityKey', 'quality')\n",
        "        self.preQualityKey = kwargs.get('preQualityKey', 'preQuality')\n",
        "        if self.classify is not None:\n",
        "            self.classFeaturesOut = self.classify.get('numClasses', None)\n",
        "            self.nbPatchesIn = self.classify.get('nbPatchesIn', 1) # Assume one patch if we do not want to concatenate patches\n",
        "        self.hyperNet = HyperNet(16,\n",
        "                                 112 * patchRate,\n",
        "                                 224 * patchRate,\n",
        "                                 112 * patchRate,\n",
        "                                 56 * patchRate,\n",
        "                                 28 * patchRate,\n",
        "                                 14 * patchRate,\n",
        "                                 7 * patchRate,\n",
        "                                 patchRate,\n",
        "                                 classFeaturesOut=self.classFeaturesOut)#.cuda()\n",
        "\n",
        "        if hyperNetPretrained is not None:\n",
        "            load_pretrained_network(self.hyperNet, defaultHyperNetWeights.get(hyperNetPretrained, hyperNetPretrained))\n",
        "        if pretrained is not None:\n",
        "            load_pretrained_network(self, defaultWeights.get(pretrained, pretrained))\n",
        "\n",
        "        if self.classify is not None:\n",
        "            self.sceneClassNet = SceneClassNet(featureInSize=self.nbPatchesIn * 112 * patchRate * self.classFeaturesOut,\n",
        "                                               **self.classify)\n",
        "            self.sceneclassnet_params = self.sceneClassNet.parameters()\n",
        "        if self.rescale is not None:\n",
        "            if 'featureInSize' in self.rescale:\n",
        "                self.classFeedback = False\n",
        "            else:\n",
        "                self.classFeedback = True\n",
        "                self.rescale.update({'featureInSize': self.classify.get('numClasses')}) # intentionally throw error if rescale is defined with infeatures and no classification parameter\n",
        "\n",
        "            self.rescaleNet = RescaleNet(**self.rescale)\n",
        "            self.rescalenet_params = self.rescaleNet.parameters()\n",
        "\n",
        "        backbone_params = list(map(id, self.hyperNet.res.parameters()))\n",
        "        self.hypernet_params = filter(lambda p: id(p) not in backbone_params, self.hyperNet.parameters())\n",
        "        self.resnet_params = filter(lambda p: id(p) in backbone_params, self.hyperNet.parameters())\n",
        "\n",
        "    def forward(self, x, index=None, *args):\n",
        "        # Generate weights for target network\n",
        "        output = self.hyperNet(x)\n",
        "\n",
        "        # Check if hyperNet returns hnFeatures\n",
        "        if isinstance(output, tuple):\n",
        "            paras, hnFeatures = output\n",
        "            hnFeatures = self._consolidate_patches(hnFeatures, self.nbPatchesIn)\n",
        "        else:\n",
        "            paras = output\n",
        "\n",
        "        if isinstance(paras, list):\n",
        "            paras = self._stack_dicts(paras)\n",
        "\n",
        "        # Building target network\n",
        "        modelTarget = TargetNet(paras)\n",
        "        for param in modelTarget.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Quality score prediction\n",
        "        inputTargetNet = paras['target_in_vec']\n",
        "        predictionsQuality = modelTarget(inputTargetNet)\n",
        "\n",
        "        predScene = None\n",
        "        outputDict = {}\n",
        "\n",
        "        if hasattr(self, 'sceneClassNet') and isinstance(output, tuple):\n",
        "            predScene = self.sceneClassNet(hnFeatures)\n",
        "            predictionsQuality = predictionsQuality.reshape(self.nbPatchesIn, -1).mean(dim=0)\n",
        "\n",
        "        outputDict[self.qualityKey] = predictionsQuality\n",
        "\n",
        "        if hasattr(self, 'rescaleNet') and hasattr(self, 'classFeedback'):\n",
        "            outputDict[self.preQualityKey] = predictionsQuality\n",
        "\n",
        "            if not self.classFeedback and index is not None:\n",
        "                index_ = one_hot(index, num_classes=self.rescale['featureInSize']).to(torch.float32)\n",
        "                scoreWeights = self.rescaleNet(index_)\n",
        "\n",
        "            elif hasattr(self, 'sceneClassNet') and isinstance(output, tuple):\n",
        "                scoreWeights = self.rescaleNet(predScene.softmax(dim=1))\n",
        "\n",
        "            else:\n",
        "                raise ValueError(\"Class feedback needs class prediction, which is not defined in this configuration\")\n",
        "\n",
        "            # FIXME: Fit with any polynomial degree instead of only manual linear fit.\n",
        "            # Re-scale the score prediction with alpha/beta\n",
        "            outputDict[self.qualityKey] = scoreWeights[:,0] * predictionsQuality + scoreWeights[:,1]\n",
        "\n",
        "        if predScene is not None:\n",
        "            return {self.classKey: predScene,\n",
        "                    **{keyOut: valueOut.unsqueeze(1) for keyOut, valueOut in outputDict.items()}}\n",
        "\n",
        "        return outputDict\n",
        "\n",
        "    @staticmethod\n",
        "    def _consolidate_patches(hnFeatures, patches_per_image):\n",
        "        # Check if hnFeatures is a list\n",
        "        if isinstance(hnFeatures, list):\n",
        "            # If first element of the list is a tensor and is 2D, stack along 1st dimension\n",
        "            if hnFeatures[0].dim() >= 2:\n",
        "                hnFeatures = torch.cat(hnFeatures, dim=0)\n",
        "            # If first element of the list is a tensor and is 1D, convert to 2D and stack along 1st dimension\n",
        "            elif hnFeatures[0].dim() == 1:\n",
        "                hnFeatures = torch.stack(hnFeatures, dim=0)\n",
        "\n",
        "        # Ensure that the total number of features is a multiple of patches_per_image\n",
        "        if hnFeatures.shape[0] % patches_per_image != 0:\n",
        "            raise ValueError(\"Total number of features is not a multiple of patches_per_image\")\n",
        "\n",
        "        # Reshape the tensor\n",
        "        consolidated_features = hnFeatures.reshape(-1, hnFeatures.shape[1] * patches_per_image)\n",
        "\n",
        "        return consolidated_features\n",
        "\n",
        "    @staticmethod\n",
        "    def _stack_dicts(dict_list):\n",
        "        # Ensure dict_list is not empty\n",
        "        if not dict_list:\n",
        "            return {}\n",
        "\n",
        "        # Create a new dictionary where each key is a stack of the corresponding values from the dictionaries in dict_list\n",
        "        stacked_dict = {key: torch.stack([d[key] for d in dict_list], dim=0) for key in dict_list[0].keys()}\n",
        "\n",
        "        return stacked_dict\n",
        "\n",
        "class FullHyperIQA(SemHyperIQA):\n",
        "    def __init__(self, patchSize, hyperNetPretrained=None, pretrained=None, classify=None, rescale=None, **kwargs):\n",
        "        super().__init__(patchSize, hyperNetPretrained, pretrained, classify, rescale, **kwargs)\n",
        "        self.weightQualityByClass = kwargs.get('weightQualityByClass', 0)\n",
        "\n",
        "    def forward(self, x, index=None, *args):\n",
        "        if self.weightQualityByClass <= 0:\n",
        "            return super().forward(x, index, *args)\n",
        "\n",
        "        # Generate weights for target network\n",
        "        output = self.hyperNet(x)\n",
        "\n",
        "        # Check if hyperNet returns hnFeatures\n",
        "        if isinstance(output, tuple):\n",
        "            paras, hnFeatures = output\n",
        "            hnFeatures = self._consolidate_patches(hnFeatures, self.nbPatchesIn)\n",
        "        else:\n",
        "            paras = output\n",
        "\n",
        "        if isinstance(paras, list):\n",
        "            paras = self._stack_dicts(paras)\n",
        "\n",
        "        # Building target network\n",
        "        modelTarget = TargetNet(paras)\n",
        "        for param in modelTarget.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Quality score prediction\n",
        "        inputTargetNet = paras['target_in_vec']\n",
        "        predictionsQuality = modelTarget(inputTargetNet)\n",
        "\n",
        "        predScene = None\n",
        "        outputDict = {}\n",
        "\n",
        "        if hasattr(self, 'sceneClassNet') and isinstance(output, tuple):\n",
        "            predScene = self.sceneClassNet(hnFeatures)\n",
        "            predictionsQuality = predictionsQuality.reshape(self.nbPatchesIn, -1).mean(dim=0)\n",
        "\n",
        "        outputDict[self.qualityKey] = predictionsQuality\n",
        "\n",
        "        if hasattr(self, 'rescaleNet') and hasattr(self, 'classFeedback'):\n",
        "\n",
        "            outputDict[self.preQualityKey] = predictionsQuality\n",
        "\n",
        "            if not self.classFeedback and index is not None:\n",
        "                index_ = one_hot(index, num_classes=self.rescale['featureInSize']).to(torch.float32)\n",
        "                scoreWeights = self.rescaleNet(index_)\n",
        "                # FIXME: Fit with any polynomial degree instead of only manual linear fit.\n",
        "                # Re-scale the score prediction with alpha/beta\n",
        "                outputDict[self.qualityKey] = scoreWeights[:,0] * predictionsQuality + scoreWeights[:,1]\n",
        "\n",
        "            elif hasattr(self, 'sceneClassNet') and isinstance(output, tuple):\n",
        "                # Extracting top-k class probabilities and indices\n",
        "                topk_probs, topk_indices = torch.topk(predScene.softmax(dim=1), self.weightQualityByClass, dim=1)\n",
        "\n",
        "                # Normalizing the top-k probabilities\n",
        "                topk_probs /= topk_probs.sum(dim=1, keepdim=True)\n",
        "\n",
        "                # Rescale quality prediction for each of the top-k classes separately\n",
        "                weighted_rescaled_qualities = []\n",
        "                for k in range(self.weightQualityByClass):\n",
        "                    one_hot_class = one_hot(topk_indices[:, k], num_classes=self.rescale['featureInSize']).to(torch.float32)\n",
        "                    scoreWeights_for_class = self.rescaleNet(one_hot_class)\n",
        "                    rescaled_quality = scoreWeights_for_class[:, 0] * predictionsQuality + scoreWeights_for_class[:, 1]\n",
        "                    weighted_rescaled_qualities.append(rescaled_quality)\n",
        "\n",
        "                # Weighted aggregation of the rescaled qualities\n",
        "                weighted_rescaled_qualities = torch.stack(weighted_rescaled_qualities, dim=1)\n",
        "                outputDict[self.qualityKey] = (weighted_rescaled_qualities * topk_probs).sum(dim=-1)\n",
        "\n",
        "            else:\n",
        "                # This should never be raised since\n",
        "                raise ValueError(\"Class feedback needs class prediction, which is not defined in this configuration\")\n",
        "\n",
        "        if predScene is not None:\n",
        "            return {self.classKey: predScene,\n",
        "                    **{keyOut: valueOut.unsqueeze(1) for keyOut, valueOut in outputDict.items()}}\n",
        "\n",
        "        return outputDict"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model SEM_HyperIQA_SO**"
      ],
      "metadata": {
        "id": "U2rghq15LldN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/PIQ2023/src/models/archs')\n",
        "\n",
        "# Now you can import your modules without import errors\n",
        "from sem_hyperiqa_util import HyperNet, RescaleNet, TargetNet, SceneClassNet\n",
        "from arch_util import load_file_from_url\n",
        "\n",
        "\n",
        "\n",
        "class SEM_HyperIQA_SO(nn.Module):\n",
        "    def __init__(self, patch_size, hyper_net_pretrained=None, pretrained=None, classify=None, **kwargs):\n",
        "        super().__init__()\n",
        "        patch_rate = patch_size // 224\n",
        "        self.classify = classify\n",
        "        self.class_features_out = None\n",
        "        self.nb_patches_in = None\n",
        "        self.quality_key = kwargs.get('quality_key', 'quality')\n",
        "\n",
        "        self.hyper_net = HyperNet(16, 112 * patch_rate, 224 * patch_rate, 112 * patch_rate, 56 * patch_rate, 28 * patch_rate, 14 * patch_rate, 7 * patch_rate, patch_rate)\n",
        "\n",
        "        if hyper_net_pretrained is not None:\n",
        "            load_pretrained_network(self.hyper_net, hyper_net_pretrained)\n",
        "        if pretrained is not None:\n",
        "            load_pretrained_network(self, pretrained)\n",
        "\n",
        "        backbone_params = list(map(id, self.hyper_net.res.parameters()))\n",
        "        self.hypernet_params = filter(lambda p: id(p) not in backbone_params, self.hyper_net.parameters())\n",
        "        self.resnet_params = filter(lambda p: id(p) in backbone_params, self.hyper_net.parameters())\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.hyper_net(x)\n",
        "\n",
        "        if isinstance(output, tuple):\n",
        "            paras, _ = output\n",
        "        else:\n",
        "            paras = output\n",
        "\n",
        "        if isinstance(paras, list):\n",
        "            paras = self._stack_dicts(paras)\n",
        "\n",
        "        model_target = TargetNet(paras)\n",
        "        for param in model_target.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        input_target_net = paras['target_in_vec']\n",
        "        predictions_quality = model_target(input_target_net)\n",
        "\n",
        "        output_dict = {self.quality_key: predictions_quality}\n",
        "\n",
        "        return output_dict\n",
        "\n",
        "    @staticmethod\n",
        "    def _stack_dicts(dict_list):\n",
        "        if not dict_list:\n",
        "            return {}\n",
        "\n",
        "        stacked_dict = {key: torch.stack([d[key] for d in dict_list], dim=0) for key in dict_list[0].keys()}\n",
        "\n",
        "        return stacked_dict\n"
      ],
      "metadata": {
        "id": "Cm7AwaU5LdKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model SEM_HyperIQA_CO**"
      ],
      "metadata": {
        "id": "rTDCDpDhLycK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Costumizing the Data"
      ],
      "metadata": {
        "id": "eODCtfAbFaQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.dataframe.iloc[idx]['IMAGE PATH']\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = torch.tensor(self.dataframe.iloc[idx]['JOD'], dtype=torch.float32)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "transform = Compose([\n",
        "    Resize((224, 224)),\n",
        "    ToTensor(),\n",
        "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nprgeDZaHwGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Score exposure scene split\n",
        "trainPath = \"/content/drive/MyDrive/Dataset/Scene_Split_train.csv\"\n",
        "train_SE_S = pd.read_csv(trainPath)\n",
        "\n",
        "testPath = \"/content/drive/MyDrive/Dataset/Scene_Split_test.csv\"\n",
        "test_SE_S = pd.read_csv(testPath)\n",
        "\n",
        "#Score exposure device split\n",
        "traindf_path = \"/content/drive/MyDrive/Dataset/device_split_train.csv\"\n",
        "train_SE_D = pd.read_csv(traindf_path)\n",
        "\n",
        "testdf_path = \"/content/drive/MyDrive/Dataset/device_split_test.csv\"\n",
        "test_SE_D = pd.read_csv(testdf_path)\n",
        "\n",
        "# SCORE DETAIL SCENE SPLİT\n",
        "train_SD_S_path = \"/content/drive/MyDrive/Dataset/Scene_Split_trai_SD_S.csv\"\n",
        "train_SD_S = pd.read_csv(train_SD_S_path)\n",
        "\n",
        "test_SD_S_path = \"/content/drive/MyDrive/Dataset/Scene_Split_test_SD_S.csv\"\n",
        "test_SD_S = pd.read_csv(test_SD_S_path)\n",
        "\n",
        "# SCORE DETAIL DEVICE SPLİT\n",
        "train_SD_D_path = \"/content/drive/MyDrive/Dataset/device_split_train_SD_D.csv\"\n",
        "train_SD_D = pd.read_csv(train_SD_D_path)\n",
        "\n",
        "test_SD_D_path = \"/content/drive/MyDrive/Dataset/device_split_testDf_SD_D.csv\"\n",
        "test_SD_D = pd.read_csv(test_SD_D_path)\n",
        "\n",
        "#SCORE OVERALL SCENE SPLIT\n",
        "train_SO_path = \"/content/drive/MyDrive/Dataset/Scene_Split_train_SO.csv\"\n",
        "train_SO_S = pd.read_csv(train_SO_path)\n",
        "\n",
        "test_SO_path = \"/content/drive/MyDrive/Dataset/Scene_Split_test_SO.csv\"\n",
        "test_SO_S = pd.read_csv(test_SO_path)\n",
        "\n",
        "#SCORE OVERALL DEVICE SPLIT\n",
        "train_SO_D_path = \"/content/drive/MyDrive/Dataset/device_split_train_SO.csv\"\n",
        "train_SO_D = pd.read_csv(train_SO_D_path)\n",
        "\n",
        "test_SO_D_path = \"/content/drive/MyDrive/Dataset/device_split_test_SO.csv\"\n",
        "test_SO_D = pd.read_csv(test_SO_D_path)\n"
      ],
      "metadata": {
        "id": "PUrhOYTzBnUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[bağlantı metni](https://)**SCORE EXPOSURE SCENE SPLIT**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TCu1x0khCY4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train_SE_S, transform=transform)\n",
        "test_dataset = CustomDataset(test_SE_S, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "FMoSfoW7CZEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SCORE EXPOSURE DEVICE SPLIT**\n"
      ],
      "metadata": {
        "id": "TGErRG3uCuhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train_SE_D, transform=transform)\n",
        "test_dataset = CustomDataset(test_SE_D, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "4pRXeb8QCusJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**italik metin*SCORE DETAIL SCENE SPLIT**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gmLX9zxtDLv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train_SD_S, transform=transform)\n",
        "test_dataset = CustomDataset(test_SD_S, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "-w5LvwX1DL77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SCORE DETAIL DEVICE SPLIT**\n"
      ],
      "metadata": {
        "id": "uehDxWnqDj6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train_SD_D, transform=transform)\n",
        "test_dataset = CustomDataset(test_SD_D, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "KB5wf2JhDkEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SCORE OVERALL SCENE SPLIT**\n"
      ],
      "metadata": {
        "id": "DdKpKci3Ds4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train_SO_S, transform=transform)\n",
        "test_dataset = CustomDataset(test_SO_S, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "mZ0JoI7IDtAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SCORE OVERALL DEVICE SPLIT**\n"
      ],
      "metadata": {
        "id": "LZHTPspsD4RG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train_SO_D, transform=transform)\n",
        "test_dataset = CustomDataset(test_SO_D, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "BI9DuGhmD4X8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training The Model"
      ],
      "metadata": {
        "id": "SRBbUk-8FWLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "def train_model(model, criterion, optimizer, train_loader, num_epochs=25):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images, labels\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs['quality'], labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "    print('Eğitim tamamlandı')\n",
        "    return model"
      ],
      "metadata": {
        "id": "TTBGKWxX_Hfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images, labels\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs['quality'], labels)\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "\n",
        "    average_loss = total_loss / len(test_loader.dataset)\n",
        "    print(f'Test Loss: {average_loss:.4f}')\n",
        "\n",
        "# Modeli test etme\n"
      ],
      "metadata": {
        "id": "7_UuvNZ6_v6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, model_name):\n",
        "    model_save_path = f'/content/drive/MyDrive/{model_name}.pth'\n",
        "    torch.save(model.state_dict(), model_save_path)\n",
        "    print(f'Model kaydedildi: {model_save_path}')"
      ],
      "metadata": {
        "id": "W9t9UfvbJB8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_the_savedmodel(model_name):\n",
        "    model_load_path = f'/content/drive/MyDrive/{model_name}.pth'\n",
        "    model_name.load_state_dict(torch.load(model_load_path))\n",
        "    model_name.eval()\n",
        "    print(f'Model yüklendi: {model_load_path}')"
      ],
      "metadata": {
        "id": "GGyTdmr6KFnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def making_csv(model, model_name, test_loader, test_df):\n",
        "    model.eval()\n",
        "    results = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            quality_scores = outputs['quality'].cpu().numpy()\n",
        "            true_jods = labels.cpu().numpy()\n",
        "            for quality_score, true_jod in zip(quality_scores, true_jods):\n",
        "                results.append((quality_score, true_jod))\n",
        "\n",
        "    results_df = pd.DataFrame(results, columns=['Predicted_Quality_Score', 'True_JOD'])\n",
        "\n",
        "    model_df = pd.concat([test_df.reset_index(drop=True), results_df], axis=1)\n",
        "\n",
        "    globals()[model_name] = model_df\n",
        "\n",
        "    output_path = f'/content/drive/MyDrive/{model_name}.csv'\n",
        "    model_df.to_csv(output_path, index=False)\n",
        "    print(f'Sonuçlar kaydedildi: {output_path}')\n",
        "    print(f'{model_name}.head():')"
      ],
      "metadata": {
        "id": "0K9p-ErLKFvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SCORE DETAIL SCENE SPLIT ON ALL THE MODEL"
      ],
      "metadata": {
        "id": "rSmmcxBfMu0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SemHyperIQA(patchSize=224, hyperNetPretrained=None)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "SemHyperIQA_SD_S = train_model(model, criterion, optimizer, train_loader, num_epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qu3NJBONJECq",
        "outputId": "d80881dd-838b-48b0-a2d7-ff84d7459c4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 1.2464\n",
            "Epoch 2/5, Loss: 0.6702\n",
            "Epoch 3/5, Loss: 0.3791\n",
            "Epoch 4/5, Loss: 0.2537\n",
            "Epoch 5/5, Loss: 0.2292\n",
            "Eğitim tamamlandı\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(SemHyperIQA_SD_S, \"SemHyperIQA_SD_S\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aMBNmQfKMTy",
        "outputId": "3cf08199-bcc8-4017-d855-88b8dc4a3b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model kaydedildi: /content/drive/MyDrive/SemHyperIQA_SD_S.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(SemHyperIQA_SD_S, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9a0NLkVKb4R",
        "outputId": "4e7d0b3e-763a-40c3-9b9f-2a53cda9626f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.3448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = FullHyperIQA(patchSize=224, hyperNetPretrained=None)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "FullHyperIQA_SD_S = train_model(model, criterion, optimizer, train_loader, num_epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNhXDnooKxl_",
        "outputId": "5473db8e-07a4-435d-863f-eb3767491fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 1.2683\n",
            "Epoch 2/5, Loss: 0.6297\n",
            "Epoch 3/5, Loss: 0.3870\n",
            "Epoch 4/5, Loss: 0.2405\n",
            "Epoch 5/5, Loss: 0.2226\n",
            "Eğitim tamamlandı\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(FullHyperIQA_SD_S, \"FullHyperIQA_SD_S\")"
      ],
      "metadata": {
        "id": "VyRK3e-iMGVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cf6c425-aac1-4d21-8439-4001f3cbbdef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model kaydedildi: /content/drive/MyDrive/FullHyperIQA_SD_S.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(FullHyperIQA_SD_S, test_loader)"
      ],
      "metadata": {
        "id": "Mj1NfmUNMI0N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf772417-854c-4bc9-80b2-291e77a15ce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.3491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QKmMsA7ez6pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SEM_HyperIQA_SO(patch_size=224, hyper_Net_Pretrained=None)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "SemHyperIQA_SO_SD_S = train_model(model, criterion, optimizer, train_loader, num_epochs=5)"
      ],
      "metadata": {
        "id": "LMEjz-JaK6ma",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "collapsed": true,
        "outputId": "40738f31-bc90-43e0-c091-871286569097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-aef575289196>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mSemHyperIQA_SO_SD_S\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-ef1b25927f03>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, train_loader, num_epochs)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'quality'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-f0f4b0070ab1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyper_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PIQ2023/src/models/archs/sem_hyperiqa_util.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PIQ2023/src/models/archs/sem_hyperiqa_util.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, imgTensorIn)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgTensorIn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mfeature_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mres_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgTensorIn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# input vector for target net\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PIQ2023/src/models/archs/sem_hyperiqa_util.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mlda_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlda3_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlda3_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0mlda_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlda4_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlda4_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PIQ2023/src/models/archs/sem_hyperiqa_util.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(SemHyperIQA_SO_SD_S, \"SemHyperIQA_SO_SD_S\")"
      ],
      "metadata": {
        "id": "QQsQnM3sMKP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(SemHyperIQA_SO_SD_S, test_loader)"
      ],
      "metadata": {
        "id": "FbrxCRsLMKS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**SCORE DETAIL DEVICE SPLIT ON ALL THE MODEL**"
      ],
      "metadata": {
        "id": "rujiy6yDNAmO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o9E6s_o87XmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(SemHyperIQA_SD_D, test_loader)"
      ],
      "metadata": {
        "id": "cRmvTllCNVBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xeWKjMuQsI4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FullHyperIQA(patchSize=224, hyperNetPretrained=None)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "FullHyperIQA_SD_D = train_model(model, criterion, optimizer, train_loader, num_epochs=5)"
      ],
      "metadata": {
        "id": "Mn22-DHHNXHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(FullHyperIQA_SD_D, \"FullHyperIQA_SD_D\")"
      ],
      "metadata": {
        "id": "YqJig-fGNXLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(FullHyperIQA_SD_D, test_loader)"
      ],
      "metadata": {
        "id": "q1X-IbEtNXPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SEM_HyperIQA_SO(patch_size=224, hyper_Net_Pretrained=None)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "SemHyperIQA_SO_SD_D = train_model(model, criterion, optimizer, train_loader, num_epochs=5)"
      ],
      "metadata": {
        "id": "nSe5QwNDNXS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(SemHyperIQA_SO_SD_D, \"SemHyperIQA_SO_SD_D\")"
      ],
      "metadata": {
        "id": "2R3ScrEjNmOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(SemHyperIQA_SO_SD_D, test_loader)"
      ],
      "metadata": {
        "id": "TtgK9DRxNmSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SCORE OVERALL SCENE SPLIT ON ALL THE MODEL**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CeU0VRhSO8bP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SemHyperIQA(patchSize=224, hyperNetPretrained=None)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "SemHyperIQA_SO_S = train_model(model, criterion, optimizer, train_loader, num_epochs=5)"
      ],
      "metadata": {
        "id": "rSlcfkxtO8mN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(SemHyperIQA_SO_S, \"SemHyperIQA_SO_S\")"
      ],
      "metadata": {
        "id": "JB9ei-p6PoyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(SemHyperIQA_SO_S, test_loader)"
      ],
      "metadata": {
        "id": "qXcmEhFOPqN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FullHyperIQA(patchSize=224, hyperNetPretrained=None)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "FullHyperIQA_SO_S = train_model(model, criterion, optimizer, train_loader, num_epochs=5)"
      ],
      "metadata": {
        "id": "tpfvbcLIPqUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(FullHyperIQA_SO_S, \"FullHyperIQA_SO_S\")"
      ],
      "metadata": {
        "id": "n-ODYpavPtMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(FullHyperIQA_SO_S, test_loader)"
      ],
      "metadata": {
        "id": "iSZfDgaXPvXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SEM_HyperIQA_SO(patch_size=224, hyper_Net_Pretrained=None)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "SemHyperIQA_SO_SO_S = train_model(model, criterion, optimizer, train_loader, num_epochs=5)"
      ],
      "metadata": {
        "id": "Be_gx5dAQuPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(SemHyperIQA_SO_SO_S, \"SemHyperIQA_SO_SO_S\")"
      ],
      "metadata": {
        "id": "obvJv2jNQuVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(SemHyperIQA_SO_SO_S, test_loader)"
      ],
      "metadata": {
        "id": "fbhhQGJLQuZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SCORE OVERALL DEVICE SPLIT ON ALL THE MODEL**"
      ],
      "metadata": {
        "id": "9TUSvkmqRS_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SemHyperIQA(patchSize=224, hyperNetPretrained=None)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "CdQDdDf4VYTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(SemHyperIQA_SO_D, \"SemHyperIQA_SO_D\")"
      ],
      "metadata": {
        "id": "kVW5iHc0RSV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(SemHyperIQA_SO_D, test_loader)"
      ],
      "metadata": {
        "id": "YzlGfVgORSZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FullHyperIQA(patchSize=224, hyperNetPretrained=None)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "FullHyperIQA_SO_D = train_model(model, criterion, optimizer, train_loader, num_epochs=5)"
      ],
      "metadata": {
        "id": "L3xHc3TcRSfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(FullHyperIQA_SO_D, \"FullHyperIQA_SO_D\")"
      ],
      "metadata": {
        "id": "Jjcu_Ty2R2h_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(FullHyperIQA_SO_D, test_loader)"
      ],
      "metadata": {
        "id": "i8GgQJ-uR2k7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEM_HyperIQA_SO_device = train_model(model, criterion, optimizer, train_loader, num_epochs=8)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OCmOb2pvrc9",
        "outputId": "32a646ed-1f2c-47ff-9085-1e9479fdb835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8, Loss: 0.4896\n",
            "Epoch 2/8, Loss: 0.3200\n",
            "Epoch 3/8, Loss: 0.2277\n",
            "Epoch 4/8, Loss: 0.1625\n",
            "Epoch 5/8, Loss: 0.1351\n",
            "Epoch 6/8, Loss: 0.1032\n",
            "Epoch 7/8, Loss: 0.0978\n",
            "Epoch 8/8, Loss: 0.0929\n",
            "Eğitim tamamlandı\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "call_the_savedmodel(SEM_HyperIQA_SO)"
      ],
      "metadata": {
        "id": "QYE8hP2kR7g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(SemHyperIQA_SO, test_loader)"
      ],
      "metadata": {
        "id": "zP21pSprR7je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Score Exposure SCENE SPLIT on all the data**"
      ],
      "metadata": {
        "id": "OajWgjxxOYFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SemHyperIQA(patchSize=224, hyperNetPretrained=None)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "trained_model_scene = train_model(model, criterion, optimizer, train_loader, num_epochs=8)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57m0OXmvStvj",
        "outputId": "f84b1880-dac6-4cf2-b4ae-762b107434d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8, Loss: 1.1413\n",
            "Epoch 2/8, Loss: 0.5870\n",
            "Epoch 3/8, Loss: 0.3390\n",
            "Epoch 4/8, Loss: 0.2968\n",
            "Epoch 5/8, Loss: 0.2043\n",
            "Epoch 6/8, Loss: 0.1831\n",
            "Epoch 7/8, Loss: 0.1605\n",
            "Epoch 8/8, Loss: 0.1469\n",
            "Eğitim tamamlandı\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(model, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zodwtSorpIZm",
        "outputId": "cd2071cf-e0fb-440e-8eb0-b46f4b9a3c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.7750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = FullHyperIQA(patchSize=224, hyperNetPretrained=None)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "FullHyperIQA_model_scene = train_model(model, criterion, optimizer, train_loader, num_epochs=8)\n"
      ],
      "metadata": {
        "id": "GN-iZTBWt5F0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "128b1112-8abf-4b45-b1a3-8b13b3a9d472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8, Loss: 0.2955\n",
            "Epoch 2/8, Loss: 0.2996\n",
            "Epoch 3/8, Loss: 0.2925\n",
            "Epoch 4/8, Loss: 0.3022\n",
            "Epoch 5/8, Loss: 0.3000\n",
            "Epoch 6/8, Loss: 0.3060\n",
            "Epoch 7/8, Loss: 0.3166\n",
            "Epoch 8/8, Loss: 0.3068\n",
            "Eğitim tamamlandı\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(FullHyperIQA_model_scene, test_loader)\n"
      ],
      "metadata": {
        "id": "JCxm4EEbul5O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "629719cd-dbbf-4ece-af50-29cfc54b4273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.2880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SEM_HyperIQA_SO(patch_size=224, hyper_Net_Pretrained=None)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "SemHyperIQA_SO?SE_S = train_model(model, criterion, optimizer, train_loader, num_epochs=8)"
      ],
      "metadata": {
        "id": "l9RC9kllTpRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(SemHyperIQA_SO_SE_S, \"SemHyperIQA_SO_SE_S\")"
      ],
      "metadata": {
        "id": "dpHlCZMETpaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(SemHyperIQA_SO_SE_S, test_loader)"
      ],
      "metadata": {
        "id": "W9yjvj9jTwnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Score Exposure DEVICE SPLIT on all the data**"
      ],
      "metadata": {
        "id": "znUca4knV0sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SemHyperIQA(patch_Size=224, hyper_Net_Pretrained=None)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "trained_model2 = train_model(model, criterion, optimizer, train_loader, num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0Pf87JZH9wD",
        "outputId": "8d655a21-1c37-4b44-d303-8a2db439514e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25, Loss: 0.7291\n",
            "Epoch 2/25, Loss: 0.3455\n",
            "Epoch 3/25, Loss: 0.2005\n",
            "Epoch 4/25, Loss: 0.1604\n",
            "Epoch 5/25, Loss: 0.1422\n",
            "Epoch 6/25, Loss: 0.1056\n",
            "Epoch 7/25, Loss: 0.0804\n",
            "Epoch 8/25, Loss: 0.0679\n",
            "Epoch 9/25, Loss: 0.0745\n",
            "Epoch 10/25, Loss: 0.0625\n",
            "Epoch 11/25, Loss: 0.0553\n",
            "Epoch 12/25, Loss: 0.0571\n",
            "Epoch 13/25, Loss: 0.0596\n",
            "Epoch 14/25, Loss: 0.0596\n",
            "Epoch 15/25, Loss: 0.0440\n",
            "Epoch 16/25, Loss: 0.0405\n",
            "Epoch 17/25, Loss: 0.0356\n",
            "Epoch 18/25, Loss: 0.0357\n",
            "Epoch 19/25, Loss: 0.0369\n",
            "Epoch 20/25, Loss: 0.0331\n",
            "Epoch 21/25, Loss: 0.0277\n",
            "Epoch 22/25, Loss: 0.0226\n",
            "Epoch 23/25, Loss: 0.0203\n",
            "Epoch 24/25, Loss: 0.0204\n",
            "Epoch 25/25, Loss: 0.0211\n",
            "Eğitim tamamlandı\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(trained_model2, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHMvF1FRrSAy",
        "outputId": "1ec0dcaf-1add-440e-e240-6b4f8f52a402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.7198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SemHyperIQA(patch_Size=224, hyper_Net_Pretrained=None)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "trained_model3 = train_model(model, criterion, optimizer, train_loader, num_epochs=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSx9UpKgNTWS",
        "outputId": "813c930f-55fb-4665-8296-8c3ca9c61231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8, Loss: 1.2441\n",
            "Epoch 2/8, Loss: 0.6231\n",
            "Epoch 3/8, Loss: 0.3808\n",
            "Epoch 4/8, Loss: 0.2629\n",
            "Epoch 5/8, Loss: 0.2113\n",
            "Epoch 6/8, Loss: 0.1562\n",
            "Epoch 7/8, Loss: 0.1435\n",
            "Epoch 8/8, Loss: 0.1454\n",
            "Eğitim tamamlandı\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test3 = test_model(trained_model3, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5osWddxeOyv",
        "outputId": "f01a7389-a8f4-4be4-ef23-c9474338ab08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.7957\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FullHyperIQA_model_device = train_model(model, criterion, optimizer, train_loader, num_epochs=8)\n"
      ],
      "metadata": {
        "id": "9xK-hvWOr7xv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79a975f4-63fa-471e-8e0e-4955963850d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8, Loss: 1.2530\n",
            "Epoch 2/8, Loss: 0.6619\n",
            "Epoch 3/8, Loss: 0.4219\n",
            "Epoch 4/8, Loss: 0.2943\n",
            "Epoch 5/8, Loss: 0.2240\n",
            "Epoch 6/8, Loss: 0.1869\n",
            "Epoch 7/8, Loss: 0.1568\n",
            "Epoch 8/8, Loss: 0.1476\n",
            "Eğitim tamamlandı\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(FullHyperIQA_model_device, test_loader)\n"
      ],
      "metadata": {
        "id": "3qCwEsgQsoXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c027e0a8-1d0b-413c-cf32-bb6f93e0e330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.7005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SEM_HyperIQA_SO(patch_Size=224, hyper_Net_Pretrained=None)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "SemHyperIQA_SO_SE_D = train_model(model, criterion, optimizer, train_loader, num_epochs=8)"
      ],
      "metadata": {
        "id": "m1yuJ4kYOVaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(SemHyperIQA_SO_SE_D, \"SemHyperIQA_SO_SE_D\")"
      ],
      "metadata": {
        "id": "VQqy73EQOVem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(SemHyperIQA_SO_SE_D, test_loader)"
      ],
      "metadata": {
        "id": "Gdmu5_h3OVjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sem_hyperiqa = SemHyperIQA(patchSize=224, hyperNetPretrained=None)\n",
        "full_hyperiqa = FullHyperIQA(patchSize=224, hyperNetPretrained=None)\n",
        "\n",
        "sem_hyperiqa_load_path = '/content/SemHyperIQA_SE_D.pth'\n",
        "full_hyperiqa_load_path = '/content/drive/MyDrive/FullHyperIQA_model_scene.pth'\n",
        "\n",
        "\n",
        "sem_hyperiqa.load_state_dict(torch.load(sem_hyperiqa_load_path))\n",
        "full_hyperiqa.load_state_dict(torch.load(full_hyperiqa_load_path))\n",
        "\n",
        "sem_hyperiqa.eval()\n",
        "full_hyperiqa.eval()\n"
      ],
      "metadata": {
        "id": "u4HO4t0LWFPg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "3954cde7-bea0-4d40-fbdf-c30d00d1ff46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 288MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-f5792d0b323a>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msem_hyperiqa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msem_hyperiqa_load_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mfull_hyperiqa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_hyperiqa_load_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0morig_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0moverall_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_is_torchscript_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m                     warnings.warn(\"'torch.load' received a zip file that looks like a TorchScript archive\"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Verify file paths\n",
        "sem_hyperiqa_load_path = '/content/SemHyperIQA_SE_D.pth'\n",
        "full_hyperiqa_load_path = '/content/drive/MyDrive/FullHyperIQA_model_scene.pth'\n",
        "\n",
        "try:\n",
        "    # Attempt to load the models\n",
        "    sem_hyperiqa.load_state_dict(torch.load(sem_hyperiqa_load_path, map_location=torch.device('cpu')))\n",
        "    full_hyperiqa.load_state_dict(torch.load(full_hyperiqa_load_path, map_location=torch.device('cpu')))\n",
        "    print(\"Models loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading models: {e}\")\n",
        "\n",
        "# To verify the file integrity (optional)\n",
        "try:\n",
        "    with open(sem_hyperiqa_load_path, 'rb') as f:\n",
        "        sem_hyperiqa_data = f.read()\n",
        "    with open(full_hyperiqa_load_path, 'rb') as f:\n",
        "        full_hyperiqa_data = f.read()\n",
        "    print(\"Files read successfully, no corruption detected.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error reading files: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3KAOu9jjFP0",
        "outputId": "be4a396a-a256-4333-9ab9-05c61d096637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models loaded successfully!\n",
            "Files read successfully, no corruption detected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
        "\n",
        "\n",
        "testDfPath =  \"/content/drive/MyDrive/Dataset/Scene_Split_test.csv\"\n",
        "testDf = pd.read_csv(testDfPath)\n",
        "\n",
        "\n",
        "transform = Compose([\n",
        "    Resize((224, 224)),\n",
        "    ToTensor(),\n",
        "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),a\n",
        "])\n",
        "\n",
        "test_dataset = CustomDataset(testDf, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "sem_hyperiqa_predictions = []\n",
        "full_hyperiqa_predictions = []\n",
        "true_values = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for images, labels in test_loader:\n",
        "    sem_hyperiqa_outputs = sem_hyperiqa(images)\n",
        "    full_hyperiqa_outputs = full_hyperiqa(images)\n",
        "\n",
        "    sem_hyperiqa_predictions.append(sem_hyperiqa_outputs['quality'].item())\n",
        "    full_hyperiqa_predictions.append(full_hyperiqa_outputs['quality'].item())\n",
        "    true_values.append(labels.item())"
      ],
      "metadata": {
        "id": "xBkt8PJrjOH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sem_hyperiqa_metrics = calculate_metrics(sem_hyperiqa_predictions, true_values)\n",
        "full_hyperiqa_metrics = calculate_metrics(full_hyperiqa_predictions, true_values)\n",
        "\n",
        "print(f\"SemHyperIQA Metrics: {sem_hyperiqa_metrics}\")\n",
        "print(f\"FullHyperIQA Metrics: {full_hyperiqa_metrics}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPF6vOYWkyaH",
        "outputId": "41a853d5-d25e-49fb-a382-9e3c1e22d46e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SemHyperIQA Metrics: (0.241263164167455, 0.23521197516819198, 0.16284007150974983, 1.0705978145813404)\n",
            "FullHyperIQA Metrics: (0.45953627403766634, 0.43820446935643603, 0.3154836595889909, 1.0156913471333686)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Performans metriklerini tabloya ekleme\n",
        "data = {\n",
        "    ('Details', 'SROCC'): [sem_hyperiqa_metrics[0], full_hyperiqa_metrics[0]],\n",
        "    ('Details', 'PLCC'): [sem_hyperiqa_metrics[1], full_hyperiqa_metrics[1]],\n",
        "    ('Details', 'KROCC'): [sem_hyperiqa_metrics[2], full_hyperiqa_metrics[2]],\n",
        "    ('Details', 'MAE'): [sem_hyperiqa_metrics[3], full_hyperiqa_metrics[3]],\n",
        "    ('Exposure', 'SROCC'): [sem_hyperiqa_metrics[0], full_hyperiqa_metrics[0]],  # Hypothetical, needs actual values\n",
        "    ('Exposure', 'PLCC'): [sem_hyperiqa_metrics[1], full_hyperiqa_metrics[1]],  # Hypothetical, needs actual values\n",
        "    ('Exposure', 'KROCC'): [sem_hyperiqa_metrics[2], full_hyperiqa_metrics[2]],  # Hypothetical, needs actual values\n",
        "    ('Exposure', 'MAE'): [sem_hyperiqa_metrics[3], full_hyperiqa_metrics[3]],  # Hypothetical, needs actual values\n",
        "    ('Overall', 'SROCC'): [sem_hyperiqa_metrics[0], full_hyperiqa_metrics[0]],  # Hypothetical, needs actual values\n",
        "    ('Overall', 'PLCC'): [sem_hyperiqa_metrics[1], full_hyperiqa_metrics[1]],  # Hypothetical, needs actual values\n",
        "    ('Overall', 'KROCC'): [sem_hyperiqa_metrics[2], full_hyperiqa_metrics[2]],  # Hypothetical, needs actual values\n",
        "    ('Overall', 'MAE'): [sem_hyperiqa_metrics[3], full_hyperiqa_metrics[3]],  # Hypothetical, needs actual values\n",
        "}\n",
        "\n",
        "# Çok katmanlı sütun başlıkları oluşturma\n",
        "columns = pd.MultiIndex.from_tuples([\n",
        "    ('Scene Split', 'Details', 'SROCC'),\n",
        "    ('Scene Split', 'Details', 'PLCC'),\n",
        "    ('Scene Split', 'Details', 'KROCC'),\n",
        "    ('Scene Split', 'Details', 'MAE'),\n",
        "    ('Scene Split', 'Exposure', 'SROCC'),\n",
        "    ('Scene Split', 'Exposure', 'PLCC'),\n",
        "    ('Scene Split', 'Exposure', 'KROCC'),\n",
        "    ('Scene Split', 'Exposure', 'MAE'),\n",
        "    ('Scene Split', 'Overall', 'SROCC'),\n",
        "    ('Scene Split', 'Overall', 'PLCC'),\n",
        "    ('Scene Split', 'Overall', 'KROCC'),\n",
        "    ('Scene Split', 'Overall', 'MAE')\n",
        "])\n",
        "\n",
        "# DataFrame'i çok katmanlı sütun başlıklarıyla oluşturma\n",
        "Scene_Split = pd.DataFrame(data, index=['SemHyperIQA', 'FullHyperIQA'])\n",
        "Scene_Split.columns = columns\n",
        "\n",
        "# İlk sütun olan Model\\Attribute'u ekleme\n",
        "Scene_Split.index.name = 'Model\\\\Attribute'\n",
        "Scene_Split.reset_index(inplace=True)\n",
        "\n",
        "# CSV dosyasına kaydetme\n",
        "Scene_Split.to_csv('/content/drive/MyDrive/Scene_Split_score.csv', index=False)\n",
        "print(f'Sonuçlar kaydedildi: /content/drive/MyDrive/Scene_Split_score.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaC3KCWTkjWc",
        "outputId": "1a6f6300-8bac-4345-8aaf-16b1466ec3f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sonuçlar kaydedildi: /content/drive/MyDrive/Scene_Split_score.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Scene_Split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "hqbK7SrkqFsL",
        "outputId": "ed119642-cc6c-40b2-e899-972ec1ba8af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Model\\Attribute Scene Split                                          \\\n",
              "                      Details                                Exposure   \n",
              "                        SROCC      PLCC     KROCC       MAE     SROCC   \n",
              "0     SemHyperIQA    0.241263  0.235212  0.162840  1.070598  0.241263   \n",
              "1    FullHyperIQA    0.459536  0.438204  0.315484  1.015691  0.459536   \n",
              "\n",
              "                                                                         \n",
              "                                  Overall                                \n",
              "       PLCC     KROCC       MAE     SROCC      PLCC     KROCC       MAE  \n",
              "0  0.235212  0.162840  1.070598  0.241263  0.235212  0.162840  1.070598  \n",
              "1  0.438204  0.315484  1.015691  0.459536  0.438204  0.315484  1.015691  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a61cbbf-abb3-460e-b5af-0af3f07268b6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Model\\Attribute</th>\n",
              "      <th colspan=\"12\" halign=\"left\">Scene Split</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th colspan=\"4\" halign=\"left\">Details</th>\n",
              "      <th colspan=\"4\" halign=\"left\">Exposure</th>\n",
              "      <th colspan=\"4\" halign=\"left\">Overall</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>SROCC</th>\n",
              "      <th>PLCC</th>\n",
              "      <th>KROCC</th>\n",
              "      <th>MAE</th>\n",
              "      <th>SROCC</th>\n",
              "      <th>PLCC</th>\n",
              "      <th>KROCC</th>\n",
              "      <th>MAE</th>\n",
              "      <th>SROCC</th>\n",
              "      <th>PLCC</th>\n",
              "      <th>KROCC</th>\n",
              "      <th>MAE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SemHyperIQA</td>\n",
              "      <td>0.241263</td>\n",
              "      <td>0.235212</td>\n",
              "      <td>0.162840</td>\n",
              "      <td>1.070598</td>\n",
              "      <td>0.241263</td>\n",
              "      <td>0.235212</td>\n",
              "      <td>0.162840</td>\n",
              "      <td>1.070598</td>\n",
              "      <td>0.241263</td>\n",
              "      <td>0.235212</td>\n",
              "      <td>0.162840</td>\n",
              "      <td>1.070598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FullHyperIQA</td>\n",
              "      <td>0.459536</td>\n",
              "      <td>0.438204</td>\n",
              "      <td>0.315484</td>\n",
              "      <td>1.015691</td>\n",
              "      <td>0.459536</td>\n",
              "      <td>0.438204</td>\n",
              "      <td>0.315484</td>\n",
              "      <td>1.015691</td>\n",
              "      <td>0.459536</td>\n",
              "      <td>0.438204</td>\n",
              "      <td>0.315484</td>\n",
              "      <td>1.015691</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a61cbbf-abb3-460e-b5af-0af3f07268b6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6a61cbbf-abb3-460e-b5af-0af3f07268b6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6a61cbbf-abb3-460e-b5af-0af3f07268b6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5bd5b7f6-4f1a-4131-82db-3eb9f075dd23\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5bd5b7f6-4f1a-4131-82db-3eb9f075dd23')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5bd5b7f6-4f1a-4131-82db-3eb9f075dd23 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_60af3f66-9a79-42a1-a812-ff09cd353e68\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('Scene_Split')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_60af3f66-9a79-42a1-a812-ff09cd353e68 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('Scene_Split');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "Scene_Split",
              "summary": "{\n  \"name\": \"Scene_Split\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": [\n        \"Model\\\\Attribute\",\n        \"\",\n        \"\"\n      ],\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"FullHyperIQA\",\n          \"SemHyperIQA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Scene Split\",\n        \"Details\",\n        \"SROCC\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15434239613990278,\n        \"min\": 0.241263164167455,\n        \"max\": 0.45953627403766634,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.45953627403766634,\n          0.241263164167455\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Scene Split\",\n        \"Details\",\n        \"PLCC\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1435373691704782,\n        \"min\": 0.23521197516819198,\n        \"max\": 0.43820446935643603,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.43820446935643603,\n          0.23521197516819198\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Scene Split\",\n        \"Details\",\n        \"KROCC\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1079353162354774,\n        \"min\": 0.16284007150974983,\n        \"max\": 0.3154836595889909,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.3154836595889909,\n          0.16284007150974983\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Scene Split\",\n        \"Details\",\n        \"MAE\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.038824735463459284,\n        \"min\": 1.0156913471333686,\n        \"max\": 1.0705978145813404,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0156913471333686,\n          1.0705978145813404\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Scene Split\",\n        \"Exposure\",\n        \"SROCC\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15434239613990278,\n        \"min\": 0.241263164167455,\n        \"max\": 0.45953627403766634,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.45953627403766634,\n          0.241263164167455\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Scene Split\",\n        \"Exposure\",\n        \"PLCC\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1435373691704782,\n        \"min\": 0.23521197516819198,\n        \"max\": 0.43820446935643603,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.43820446935643603,\n          0.23521197516819198\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Scene Split\",\n        \"Exposure\",\n        \"KROCC\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1079353162354774,\n        \"min\": 0.16284007150974983,\n        \"max\": 0.3154836595889909,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.3154836595889909,\n          0.16284007150974983\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Scene Split\",\n        \"Exposure\",\n        \"MAE\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.038824735463459284,\n        \"min\": 1.0156913471333686,\n        \"max\": 1.0705978145813404,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0156913471333686,\n          1.0705978145813404\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Scene Split\",\n        \"Overall\",\n        \"SROCC\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15434239613990278,\n        \"min\": 0.241263164167455,\n        \"max\": 0.45953627403766634,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.45953627403766634,\n          0.241263164167455\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Scene Split\",\n        \"Overall\",\n        \"PLCC\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1435373691704782,\n        \"min\": 0.23521197516819198,\n        \"max\": 0.43820446935643603,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.43820446935643603,\n          0.23521197516819198\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Scene Split\",\n        \"Overall\",\n        \"KROCC\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1079353162354774,\n        \"min\": 0.16284007150974983,\n        \"max\": 0.3154836595889909,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.3154836595889909,\n          0.16284007150974983\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Scene Split\",\n        \"Overall\",\n        \"MAE\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.038824735463459284,\n        \"min\": 1.0156913471333686,\n        \"max\": 1.0705978145813404,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0156913471333686,\n          1.0705978145813404\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Verileri bir DataFrame olarak oluşturun\n",
        "data = {\n",
        "    'Model': ['SemHyperIQA', 'FullHyperIQA'],\n",
        "    'Details_SROCC': [0.241263, 0.459536],\n",
        "    'Details_PLCC': [0.235212, 0.438204],\n",
        "    'Details_KROCC': [0.162840, 0.315484],\n",
        "    'Details_MAE': [1.070598, 1.015691],\n",
        "    'Exposure_SROCC': [0.241263, 0.459536],\n",
        "    'Exposure_PLCC': [0.235212, 0.438204],\n",
        "    'Exposure_KROCC': [0.162840, 0.315484],\n",
        "    'Exposure_MAE': [1.070598, 1.015691],\n",
        "    'Overall_SROCC': [0.241263, 0.459536],\n",
        "    'Overall_PLCC': [0.235212, 0.438204],\n",
        "    'Overall_KROCC': [0.162840, 0.315484],\n",
        "    'Overall_MAE': [1.070598, 1.015691]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Soft renk paleti\n",
        "colors = ['#657b9b', '#44a0a0', '#65c282', '#5b8a3c']\n",
        "\n",
        "# Bar chart oluşturma\n",
        "metrics = ['SROCC', 'PLCC', 'KROCC', 'MAE']\n",
        "categories = ['Details', 'Exposure', 'Overall']\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=len(categories), figsize=(18, 6), sharey=True)\n",
        "\n",
        "for i, category in enumerate(categories):\n",
        "    ax = axes[i]\n",
        "    x = df['Model']\n",
        "    width = 0.2  # Bar genişliği\n",
        "    positions = range(len(df))\n",
        "\n",
        "    for j, metric in enumerate(metrics):\n",
        "        ax.bar([p + j * width for p in positions], df[f'{category}_{metric}'], width=width, label=metric, color=colors[j])\n",
        "\n",
        "    ax.set_title(category)\n",
        "    ax.set_xlabel('Model')\n",
        "    ax.set_xticks([p + 1.5 * width for p in positions])\n",
        "    ax.set_xticklabels(df['Model'])\n",
        "    if i == 0:\n",
        "        ax.set_ylabel('Value')\n",
        "    ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "sFOAVFms1HaI",
        "outputId": "75140b81-efbe-42a7-ed3d-c1e8eb19d61e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x600 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Verify file paths\n",
        "sem_hyperiqa_load_path = \"/content/drive/MyDrive/SemHyperIQA_SD_S.pth\"\n",
        "full_hyperiqa_load_path = \"/content/drive/MyDrive/FullHyperIQA_SD_S.pth\"\n",
        "\n",
        "try:\n",
        "    # Attempt to load the models\n",
        "    sem_hyperiqa.load_state_dict(torch.load(sem_hyperiqa_load_path, map_location=torch.device('cpu')))\n",
        "    full_hyperiqa.load_state_dict(torch.load(full_hyperiqa_load_path, map_location=torch.device('cpu')))\n",
        "    print(\"Models loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading models: {e}\")\n",
        "\n",
        "# To verify the file integrity (optional)\n",
        "try:\n",
        "    with open(sem_hyperiqa_load_path, 'rb') as f:\n",
        "        sem_hyperiqa_data = f.read()\n",
        "    with open(full_hyperiqa_load_path, 'rb') as f:\n",
        "        full_hyperiqa_data = f.read()\n",
        "    print(\"Files read successfully, no corruption detected.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error reading files: {e}\")\n"
      ],
      "metadata": {
        "id": "enrruWSbk0Sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sem_hyperiqa_metrics = calculate_metrics(sem_hyperiqa_predictions, true_values)\n",
        "full_hyperiqa_metrics = calculate_metrics(full_hyperiqa_predictions, true_values)\n",
        "\n",
        "print(f\"SemHyperIQA Metrics: {sem_hyperiqa_metrics}\")\n",
        "print(f\"FullHyperIQA Metrics: {full_hyperiqa_metrics}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj3a7EHxmMlW",
        "outputId": "5f4334fa-467f-4939-bbbb-17be9c823cce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SemHyperIQA Metrics: (0.241263164167455, 0.23521197516819198, 0.16284007150974983, 1.0705978145813404)\n",
            "FullHyperIQA Metrics: (0.45953627403766634, 0.43820446935643603, 0.3154836595889909, 1.0156913471333686)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Performans metriklerini tabloya ekleme\n",
        "data = {\n",
        "    ('Details', 'SROCC'): [sem_hyperiqa_metrics[0], full_hyperiqa_metrics[0]],\n",
        "    ('Details', 'PLCC'): [sem_hyperiqa_metrics[1], full_hyperiqa_metrics[1]],\n",
        "    ('Details', 'KROCC'): [sem_hyperiqa_metrics[2], full_hyperiqa_metrics[2]],\n",
        "    ('Details', 'MAE'): [sem_hyperiqa_metrics[3], full_hyperiqa_metrics[3]],\n",
        "    ('Exposure', 'SROCC'): [sem_hyperiqa_metrics[0], full_hyperiqa_metrics[0]],  # Hypothetical, needs actual values\n",
        "    ('Exposure', 'PLCC'): [sem_hyperiqa_metrics[1], full_hyperiqa_metrics[1]],  # Hypothetical, needs actual values\n",
        "    ('Exposure', 'KROCC'): [sem_hyperiqa_metrics[2], full_hyperiqa_metrics[2]],  # Hypothetical, needs actual values\n",
        "    ('Exposure', 'MAE'): [sem_hyperiqa_metrics[3], full_hyperiqa_metrics[3]],  # Hypothetical, needs actual values\n",
        "    ('Overall', 'SROCC'): [sem_hyperiqa_metrics[0], full_hyperiqa_metrics[0]],  # Hypothetical, needs actual values\n",
        "    ('Overall', 'PLCC'): [sem_hyperiqa_metrics[1], full_hyperiqa_metrics[1]],  # Hypothetical, needs actual values\n",
        "    ('Overall', 'KROCC'): [sem_hyperiqa_metrics[2], full_hyperiqa_metrics[2]],  # Hypothetical, needs actual values\n",
        "    ('Overall', 'MAE'): [sem_hyperiqa_metrics[3], full_hyperiqa_metrics[3]],  # Hypothetical, needs actual values\n",
        "}\n",
        "\n",
        "# Çok katmanlı sütun başlıkları oluşturma\n",
        "columns = pd.MultiIndex.from_tuples([\n",
        "    ('Device Split', 'Details', 'SROCC'),\n",
        "    ('Device Split', 'Details', 'PLCC'),\n",
        "    ('Device Split', 'Details', 'KROCC'),\n",
        "    ('Device Split', 'Details', 'MAE'),\n",
        "    ('Device Split', 'Exposure', 'SROCC'),\n",
        "    ('Device Split', 'Exposure', 'PLCC'),\n",
        "    ('Device Split', 'Exposure', 'KROCC'),\n",
        "    ('Device Split', 'Exposure', 'MAE'),\n",
        "    ('Device Split', 'Overall', 'SROCC'),\n",
        "    ('Device Split', 'Overall', 'PLCC'),\n",
        "    ('Device Split', 'Overall', 'KROCC'),\n",
        "    ('Device Split', 'Overall', 'MAE')\n",
        "])\n",
        "\n",
        "# DataFrame'i çok katmanlı sütun başlıklarıyla oluşturma\n",
        "Scene_Split = pd.DataFrame(data, index=['SemHyperIQA', 'FullHyperIQA'])\n",
        "Scene_Split.columns = columns\n",
        "\n",
        "# İlk sütun olan Model\\Attribute'u ekleme\n",
        "Device_Split.index.name = 'Model\\\\Attribute'\n",
        "Device_Split.reset_index(inplace=True)\n",
        "\n",
        "# CSV dosyasına kaydetme\n",
        "Device_Split.to_csv('/content/drive/MyDrive/Device_Split_score.csv', index=False)\n",
        "print(f'Sonuçlar kaydedildi: /content/drive/MyDrive/Device_Split_score.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Oiu0HfzImN9V",
        "outputId": "53d3af8b-15ec-4e79-fa4b-4a15afcbeeec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Device_Split' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-8f36586a5c88>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# İlk sütun olan Model\\Attribute'u ekleme\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mDevice_Split\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Model\\\\Attribute'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mDevice_Split\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Device_Split' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Verify file paths\n",
        "sem_hyperiqa_load_path = '/content/SemHyperIQA_SE_D.pth'\n",
        "full_hyperiqa_load_path = '/content/drive/MyDrive/FullHyperIQA_model_scene.pth'\n",
        "\n",
        "try:\n",
        "    # Attempt to load the models\n",
        "    sem_hyperiqa.load_state_dict(torch.load(sem_hyperiqa_load_path, map_location=torch.device('cpu')))\n",
        "    full_hyperiqa.load_state_dict(torch.load(full_hyperiqa_load_path, map_location=torch.device('cpu')))\n",
        "    print(\"Models loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading models: {e}\")\n",
        "\n",
        "# To verify the file integrity (optional)\n",
        "try:\n",
        "    with open(sem_hyperiqa_load_path, 'rb') as f:\n",
        "        sem_hyperiqa_data = f.read()\n",
        "    with open(full_hyperiqa_load_path, 'rb') as f:\n",
        "        full_hyperiqa_data = f.read()\n",
        "    print(\"Files read successfully, no corruption detected.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error reading files: {e}\")"
      ],
      "metadata": {
        "id": "tcrXEXVjmOk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
        "\n",
        "\n",
        "testDfPath =  \"/content/drive/MyDrive/Dataset/Scene_Split_test_SD_S.csv\"\n",
        "testDf = pd.read_csv(testDfPath)\n",
        "\n",
        "\n",
        "transform = Compose([\n",
        "    Resize((224, 224)),\n",
        "    ToTensor(),\n",
        "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),a\n",
        "])\n",
        "\n",
        "test_dataset = CustomDataset(testDf, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "sem_hyperiqa_predictions = []\n",
        "full_hyperiqa_predictions = []\n",
        "true_values = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for images, labels in test_loader:\n",
        "    sem_hyperiqa_outputs = sem_hyperiqa(images)\n",
        "    full_hyperiqa_outputs = full_hyperiqa(images)\n",
        "\n",
        "    sem_hyperiqa_predictions.append(sem_hyperiqa_outputs['quality'].item())\n",
        "    full_hyperiqa_predictions.append(full_hyperiqa_outputs['quality'].item())\n",
        "    true_values.append(labels.item())"
      ],
      "metadata": {
        "id": "6geavuu7l24F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BJ9BzUZimKfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "THESE ARE FOR COMPARING\n"
      ],
      "metadata": {
        "id": "iQRDJ5J8WFdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sem_hyperiqa = SemHyperIQA(patchSize=224, hyperNetPretrained=None)\n",
        "full_hyperiqa = FullHyperIQA(patchSize=224, hyperNetPretrained=None)\n",
        "\n",
        "sem_hyperiqa_load_path = '/content/drive/MyDrive/saved_model3.pth'\n",
        "full_hyperiqa_load_path = '/content/drive/MyDrive/FullHyperIQA_model_device.pth'\n",
        "\n",
        "sem_hyperiqa.load_state_dict(torch.load(sem_hyperiqa_load_path))\n",
        "full_hyperiqa.load_state_dict(torch.load(full_hyperiqa_load_path))\n",
        "\n",
        "sem_hyperiqa.eval()\n",
        "full_hyperiqa.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MT0KRtUY9FSu",
        "outputId": "0ae9dd47-6ba5-43e5-8e49-fe7f98badfee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FullHyperIQA(\n",
              "  (hyperNet): HyperNet(\n",
              "    (res): ResNetBackbone(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (lda1_pool): Sequential(\n",
              "        (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
              "      )\n",
              "      (lda1_fc): Linear(in_features=1024, out_features=16, bias=True)\n",
              "      (lda2_pool): Sequential(\n",
              "        (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
              "      )\n",
              "      (lda2_fc): Linear(in_features=512, out_features=16, bias=True)\n",
              "      (lda3_pool): Sequential(\n",
              "        (0): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
              "      )\n",
              "      (lda3_fc): Linear(in_features=256, out_features=16, bias=True)\n",
              "      (lda4_pool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
              "      (lda4_fc): Linear(in_features=2048, out_features=176, bias=True)\n",
              "    )\n",
              "    (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (conv1): Sequential(\n",
              "      (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "    (fc1w_conv): Conv2d(112, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (fc1b_fc): Linear(in_features=112, out_features=112, bias=True)\n",
              "    (fc2w_conv): Conv2d(112, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (fc2b_fc): Linear(in_features=112, out_features=56, bias=True)\n",
              "    (fc3w_conv): Conv2d(112, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (fc3b_fc): Linear(in_features=112, out_features=28, bias=True)\n",
              "    (fc4w_conv): Conv2d(112, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (fc4b_fc): Linear(in_features=112, out_features=14, bias=True)\n",
              "    (fc5w_fc): Linear(in_features=112, out_features=14, bias=True)\n",
              "    (fc5b_fc): Linear(in_features=112, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import spearmanr, pearsonr, kendalltau\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "def calculate_metrics(predictions, targets):\n",
        "    srocc, _ = spearmanr(predictions, targets)\n",
        "    plcc, _ = pearsonr(predictions, targets)\n",
        "    krocc, _ = kendalltau(predictions, targets)\n",
        "    mea = mean_absolute_error(predictions, targets)\n",
        "    return srocc, plcc, krocc, mea"
      ],
      "metadata": {
        "id": "MRT0pLMo_8cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testDfPath = \"/content/drive/MyDrive/Dataset/device_split_test.csv\"\n",
        "testDf = pd.read_csv(testDfPath)\n",
        "\n",
        "transform = Compose([\n",
        "    Resize((224, 224)),\n",
        "    ToTensor(),\n",
        "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "test_dataset = CustomDataset(testDf, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "sem_hyperiqa_predictions = []\n",
        "full_hyperiqa_predictions = []\n",
        "true_values = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for images, labels in test_loader:\n",
        "    sem_hyperiqa_outputs = sem_hyperiqa(images)\n",
        "    full_hyperiqa_outputs = full_hyperiqa(images)\n",
        "\n",
        "    sem_hyperiqa_predictions.append(sem_hyperiqa_outputs['quality'].item())\n",
        "    full_hyperiqa_predictions.append(full_hyperiqa_outputs['quality'].item())\n",
        "    true_values.append(labels.item())"
      ],
      "metadata": {
        "id": "pIuP5tAJ9p8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sem_hyperiqa_metrics = calculate_metrics(sem_hyperiqa_predictions, true_values)\n",
        "full_hyperiqa_metrics = calculate_metrics(full_hyperiqa_predictions, true_values)\n",
        "\n",
        "print(f\"SemHyperIQA Metrics: {sem_hyperiqa_metrics}\")\n",
        "print(f\"FullHyperIQA Metrics: {full_hyperiqa_metrics}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geg3veNPLaFB",
        "outputId": "af97766a-522b-4d50-b6f8-ddab56f0a16b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SemHyperIQA Metrics: (0.8098206906796929, 0.8176933318663235, 0.6189243938191107, 0.6689085342151605)\n",
            "FullHyperIQA Metrics: (0.8123872509648077, 0.8174008261237455, 0.6221459248517389, 0.622637875772766)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rTCykC9_kxWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Performans metriklerini tabloya ekleme\n",
        "data = {\n",
        "    ('Details', 'SROCC'): [sem_hyperiqa_metrics[0], full_hyperiqa_metrics[0]],\n",
        "    ('Details', 'PLCC'): [sem_hyperiqa_metrics[1], full_hyperiqa_metrics[1]],\n",
        "    ('Details', 'KROCC'): [sem_hyperiqa_metrics[2], full_hyperiqa_metrics[2]],\n",
        "    ('Details', 'MAE'): [sem_hyperiqa_metrics[3], full_hyperiqa_metrics[3]],\n",
        "    ('Exposure', 'SROCC'): [sem_hyperiqa_metrics[0], full_hyperiqa_metrics[0]],  # Hypothetical, needs actual values\n",
        "    ('Exposure', 'PLCC'): [sem_hyperiqa_metrics[1], full_hyperiqa_metrics[1]],  # Hypothetical, needs actual values\n",
        "    ('Exposure', 'KROCC'): [sem_hyperiqa_metrics[2], full_hyperiqa_metrics[2]],  # Hypothetical, needs actual values\n",
        "    ('Exposure', 'MAE'): [sem_hyperiqa_metrics[3], full_hyperiqa_metrics[3]],  # Hypothetical, needs actual values\n",
        "    ('Overall', 'SROCC'): [sem_hyperiqa_metrics[0], full_hyperiqa_metrics[0]],  # Hypothetical, needs actual values\n",
        "    ('Overall', 'PLCC'): [sem_hyperiqa_metrics[1], full_hyperiqa_metrics[1]],  # Hypothetical, needs actual values\n",
        "    ('Overall', 'KROCC'): [sem_hyperiqa_metrics[2], full_hyperiqa_metrics[2]],  # Hypothetical, needs actual values\n",
        "    ('Overall', 'MAE'): [sem_hyperiqa_metrics[3], full_hyperiqa_metrics[3]],  # Hypothetical, needs actual values\n",
        "}\n",
        "\n",
        "# Çok katmanlı sütun başlıkları oluşturma\n",
        "columns = pd.MultiIndex.from_tuples([\n",
        "    ('Device Split', 'Details', 'SROCC'),\n",
        "    ('Device Split', 'Details', 'PLCC'),\n",
        "    ('Device Split', 'Details', 'KROCC'),\n",
        "    ('Device Split', 'Details', 'MAE'),\n",
        "    ('Device Split', 'Exposure', 'SROCC'),\n",
        "    ('Device Split', 'Exposure', 'PLCC'),\n",
        "    ('Device Split', 'Exposure', 'KROCC'),\n",
        "    ('Device Split', 'Exposure', 'MAE'),\n",
        "    ('Device Split', 'Overall', 'SROCC'),\n",
        "    ('Device Split', 'Overall', 'PLCC'),\n",
        "    ('Device Split', 'Overall', 'KROCC'),\n",
        "    ('Device Split', 'Overall', 'MAE')\n",
        "])\n",
        "\n",
        "# DataFrame'i çok katmanlı sütun başlıklarıyla oluşturma\n",
        "Device_Split = pd.DataFrame(data, index=['SemHyperIQA', 'FullHyperIQA'])\n",
        "Device_Split.columns = columns\n",
        "\n",
        "# İlk sütun olan Model\\Attribute'u ekleme\n",
        "Device_Split.index.name = 'Model\\\\Attribute'\n",
        "Device_Split.reset_index(inplace=True)\n",
        "\n",
        "# CSV dosyasına kaydetme\n",
        "Device_Split.to_csv('/content/drive/MyDrive/Device_Split_score.csv', index=False)\n",
        "print(f'Sonuçlar kaydedildi: /content/drive/MyDrive/Device_Split_score.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muvBBxGwAxtF",
        "outputId": "9013a4ef-50f9-4a73-91f2-300a19487ca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sonuçlar kaydedildi: /content/drive/MyDrive/Device_Split_score.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np  # For generating mock data\n",
        "\n",
        "# Data definition\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# New data\n",
        "data = {\n",
        "    'Details': {\n",
        "        'SROCC': [0.241263, 0.459536],\n",
        "        'PLCC': [0.235212, 0.438204],\n",
        "        'KROCC': [0.162840, 0.315484],\n",
        "        'MAE': [1.070598, 1.015691]\n",
        "    },\n",
        "    'Exposure': {\n",
        "        'SROCC': [0.241263, 0.459536],\n",
        "        'PLCC': [0.235212, 0.438204],\n",
        "        'KROCC': [0.162840, 0.315484],\n",
        "        'MAE': [1.070598, 1.015691]\n",
        "    },\n",
        "    'Overall': {\n",
        "        'SROCC': [0.241263, 0.459536],\n",
        "        'PLCC': [0.235212, 0.438204],\n",
        "        'KROCC': [0.162840, 0.315484],\n",
        "        'MAE': [1.070598, 1.015691]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Models as index\n",
        "models = ['SemHyperIQA', 'FullHyperIQA']\n",
        "\n",
        "# Creating DataFrame with MultiIndex\n",
        "index = pd.MultiIndex.from_product([data.keys(), data['Details'].keys()], names=['Attribute', 'Metric'])\n",
        "df = pd.DataFrame([data[attr][metric] for attr in data for metric in data[attr]], index=index, columns=models).T\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)\n",
        "\n",
        "# Optionally, you can visualize this DataFrame as well, using the previous example's visualization code.\n",
        "\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Scatter plot\n",
        "sns.scatterplot(data=df, x='JOD Range', y='CI Median', hue='Attribute', style='Attribute', markers=True, palette='viridis', s=100)\n",
        "\n",
        "# Density plot addition\n",
        "sns.kdeplot(data=df, x='JOD Range', hue='Attribute', fill=True, common_norm=False, alpha=0.4, linewidth=2)\n",
        "\n",
        "plt.title('Attribute Analysis with JOD Range and CI Median')\n",
        "plt.xlabel('JOD Range')\n",
        "plt.ylabel('CI Median')\n",
        "plt.legend(title='Attribute')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "MlAPAx5MkhPA",
        "outputId": "67b8825d-b5d5-479b-8790-1e6a3d599a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attribute      Details                                Exposure            \\\n",
            "Metric           SROCC      PLCC     KROCC       MAE     SROCC      PLCC   \n",
            "SemHyperIQA   0.241263  0.235212  0.162840  1.070598  0.241263  0.235212   \n",
            "FullHyperIQA  0.459536  0.438204  0.315484  1.015691  0.459536  0.438204   \n",
            "\n",
            "Attribute                          Overall                                \n",
            "Metric           KROCC       MAE     SROCC      PLCC     KROCC       MAE  \n",
            "SemHyperIQA   0.162840  1.070598  0.241263  0.235212  0.162840  1.070598  \n",
            "FullHyperIQA  0.315484  1.015691  0.459536  0.438204  0.315484  1.015691  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Could not interpret value `JOD Range` for `x`. An entry with this name does not appear in `data`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-da870314343d>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# Scatter plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatterplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'JOD Range'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'CI Median'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Attribute'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Attribute'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'viridis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Density plot addition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/relational.py\u001b[0m in \u001b[0;36mscatterplot\u001b[0;34m(data, x, y, hue, size, style, palette, hue_order, hue_norm, sizes, size_order, size_norm, markers, style_order, legend, ax, **kwargs)\u001b[0m\n\u001b[1;32m    608\u001b[0m ):\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     p = _ScatterPlotter(\n\u001b[0m\u001b[1;32m    611\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/relational.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, variables, legend)\u001b[0m\n\u001b[1;32m    389\u001b[0m         )\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;31m# information for numeric axes would be information about log scales.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_ordered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# alt., used DefaultDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;31m# TODO Lots of tests assume that these are called to initialize the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/_base.py\u001b[0m in \u001b[0;36massign_variables\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0;31m# to centralize / standardize data consumption logic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"long\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0mplot_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlotData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/_core/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_data_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/_core/data.py\u001b[0m in \u001b[0;36m_assign_variables\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                     \u001b[0merr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"An entry with this name does not appear in `data`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Could not interpret value `JOD Range` for `x`. An entry with this name does not appear in `data`."
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZVPqpjhFzbFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Device_Split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "fBytfx99NPB8",
        "outputId": "7c58d6b9-b6dc-4fa6-a381-33c3cbfb032a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Model\\Attribute Device Split                                          \\\n",
              "                       Details                                Exposure   \n",
              "                         SROCC      PLCC     KROCC       MAE     SROCC   \n",
              "0     SemHyperIQA     0.809821  0.817693  0.618924  0.668909  0.809821   \n",
              "1    FullHyperIQA     0.812387  0.817401  0.622146  0.622638  0.812387   \n",
              "\n",
              "                                                                         \n",
              "                                  Overall                                \n",
              "       PLCC     KROCC       MAE     SROCC      PLCC     KROCC       MAE  \n",
              "0  0.817693  0.618924  0.668909  0.809821  0.817693  0.618924  0.668909  \n",
              "1  0.817401  0.622146  0.622638  0.812387  0.817401  0.622146  0.622638  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-618eb904-c68e-4289-b107-c02029cefd97\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Model\\Attribute</th>\n",
              "      <th colspan=\"12\" halign=\"left\">Device Split</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th colspan=\"4\" halign=\"left\">Details</th>\n",
              "      <th colspan=\"4\" halign=\"left\">Exposure</th>\n",
              "      <th colspan=\"4\" halign=\"left\">Overall</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>SROCC</th>\n",
              "      <th>PLCC</th>\n",
              "      <th>KROCC</th>\n",
              "      <th>MAE</th>\n",
              "      <th>SROCC</th>\n",
              "      <th>PLCC</th>\n",
              "      <th>KROCC</th>\n",
              "      <th>MAE</th>\n",
              "      <th>SROCC</th>\n",
              "      <th>PLCC</th>\n",
              "      <th>KROCC</th>\n",
              "      <th>MAE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SemHyperIQA</td>\n",
              "      <td>0.809821</td>\n",
              "      <td>0.817693</td>\n",
              "      <td>0.618924</td>\n",
              "      <td>0.668909</td>\n",
              "      <td>0.809821</td>\n",
              "      <td>0.817693</td>\n",
              "      <td>0.618924</td>\n",
              "      <td>0.668909</td>\n",
              "      <td>0.809821</td>\n",
              "      <td>0.817693</td>\n",
              "      <td>0.618924</td>\n",
              "      <td>0.668909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FullHyperIQA</td>\n",
              "      <td>0.812387</td>\n",
              "      <td>0.817401</td>\n",
              "      <td>0.622146</td>\n",
              "      <td>0.622638</td>\n",
              "      <td>0.812387</td>\n",
              "      <td>0.817401</td>\n",
              "      <td>0.622146</td>\n",
              "      <td>0.622638</td>\n",
              "      <td>0.812387</td>\n",
              "      <td>0.817401</td>\n",
              "      <td>0.622146</td>\n",
              "      <td>0.622638</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-618eb904-c68e-4289-b107-c02029cefd97')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-618eb904-c68e-4289-b107-c02029cefd97 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-618eb904-c68e-4289-b107-c02029cefd97');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7dc5eaef-c2ac-4da9-bfa4-2dc928726c43\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7dc5eaef-c2ac-4da9-bfa4-2dc928726c43')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7dc5eaef-c2ac-4da9-bfa4-2dc928726c43 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_970d1dba-72e2-4f0c-a404-a8336957e59b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('Device_Split')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_970d1dba-72e2-4f0c-a404-a8336957e59b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('Device_Split');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "Device_Split",
              "summary": "{\n  \"name\": \"Device_Split\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": [\n        \"Model\\\\Attribute\",\n        \"\",\n        \"\"\n      ],\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"FullHyperIQA\",\n          \"SemHyperIQA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Device Split\",\n        \"Details\",\n        \"SROCC\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0018148321819287652,\n        \"min\": 0.8098206906796929,\n        \"max\": 0.8123872509648077,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8123872509648077,\n          0.8098206906796929\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Device Split\",\n        \"Details\",\n        \"PLCC\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0002068327941129087,\n        \"min\": 0.8174008261237455,\n        \"max\": 0.8176933318663235,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8174008261237455,\n          0.8176933318663235\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Device Split\",\n        \"Details\",\n        \"KROCC\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0022779664389743245,\n        \"min\": 0.6189243938191107,\n        \"max\": 0.6221459248517389,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.6221459248517389,\n          0.6189243938191107\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Device Split\",\n        \"Details\",\n        \"MAE\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.032718296354583745,\n        \"min\": 0.622637875772766,\n        \"max\": 0.6689085342151605,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.622637875772766,\n          0.6689085342151605\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Device Split\",\n        \"Exposure\",\n        \"SROCC\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0018148321819287652,\n        \"min\": 0.8098206906796929,\n        \"max\": 0.8123872509648077,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8123872509648077,\n          0.8098206906796929\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Device Split\",\n        \"Exposure\",\n        \"PLCC\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0002068327941129087,\n        \"min\": 0.8174008261237455,\n        \"max\": 0.8176933318663235,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8174008261237455,\n          0.8176933318663235\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Device Split\",\n        \"Exposure\",\n        \"KROCC\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0022779664389743245,\n        \"min\": 0.6189243938191107,\n        \"max\": 0.6221459248517389,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.6221459248517389,\n          0.6189243938191107\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Device Split\",\n        \"Exposure\",\n        \"MAE\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.032718296354583745,\n        \"min\": 0.622637875772766,\n        \"max\": 0.6689085342151605,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.622637875772766,\n          0.6689085342151605\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Device Split\",\n        \"Overall\",\n        \"SROCC\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0018148321819287652,\n        \"min\": 0.8098206906796929,\n        \"max\": 0.8123872509648077,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8123872509648077,\n          0.8098206906796929\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Device Split\",\n        \"Overall\",\n        \"PLCC\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0002068327941129087,\n        \"min\": 0.8174008261237455,\n        \"max\": 0.8176933318663235,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8174008261237455,\n          0.8176933318663235\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Device Split\",\n        \"Overall\",\n        \"KROCC\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0022779664389743245,\n        \"min\": 0.6189243938191107,\n        \"max\": 0.6221459248517389,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.6221459248517389,\n          0.6189243938191107\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Device Split\",\n        \"Overall\",\n        \"MAE\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.032718296354583745,\n        \"min\": 0.622637875772766,\n        \"max\": 0.6689085342151605,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.622637875772766,\n          0.6689085342151605\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Verileri bir DataFrame olarak oluşturun\n",
        "data = {\n",
        "    'Model': ['SemHyperIQA', 'FullHyperIQA'],\n",
        "    'Details_SROCC': [0.809821, 0.812387],\n",
        "    'Details_PLCC': [0.817693, 0.817401],\n",
        "    'Details_KROCC': [0.618924, 0.622146],\n",
        "    'Details_MAE': [0.668909, 0.622638],\n",
        "    'Exposure_SROCC': [0.809821, 0.812387],\n",
        "    'Exposure_PLCC': [0.817693, 0.817401],\n",
        "    'Exposure_KROCC': [0.618924, 0.622146],\n",
        "    'Exposure_MAE': [0.668909, 0.622638],\n",
        "    'Overall_SROCC': [0.809821, 0.812387],\n",
        "    'Overall_PLCC': [0.817693, 0.817401],\n",
        "    'Overall_KROCC': [0.618924, 0.622146],\n",
        "    'Overall_MAE': [0.668909, 0.622638]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Soft renk paleti\n",
        "colors = ['#657b9b', '#44a0a0', '#65c282', '#5b8a3c']\n",
        "\n",
        "# Bar chart oluşturma\n",
        "metrics = ['SROCC', 'PLCC', 'KROCC', 'MAE']\n",
        "categories = ['Details', 'Exposure', 'Overall']\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=len(categories), figsize=(18, 6), sharey=True)\n",
        "\n",
        "for i, category in enumerate(categories):\n",
        "    ax = axes[i]\n",
        "    x = df['Model']\n",
        "    width = 0.2  # Bar genişliği\n",
        "    positions = range(len(df))\n",
        "\n",
        "    for j, metric in enumerate(metrics):\n",
        "        ax.bar([p + j * width for p in positions], df[f'{category}_{metric}'], width=width, label=metric, color=colors[j])\n",
        "\n",
        "    ax.set_title(category)\n",
        "    ax.set_xlabel('Model')\n",
        "    ax.set_xticks([p + 1.5 * width for p in positions])\n",
        "    ax.set_xticklabels(df['Model'])\n",
        "    if i == 0:\n",
        "        ax.set_ylabel('Value')\n",
        "    ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "ELNmBbvS3IH8",
        "outputId": "fc6f1508-5642-4a0f-bcba-1f7fbe090ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x600 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_results(results, title):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.scatter(results['Actual'], results['Predicted'], alpha=0.5)\n",
        "    plt.plot([results['Actual'].min(), results['Actual'].max()],\n",
        "             [results['Actual'].min(), results['Actual'].max()],\n",
        "             'r--', lw=2)\n",
        "    plt.xlabel('Actual')\n",
        "    plt.ylabel('Predicted')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "plot_results(SEM_HyperIQA, 'SEM_HyperIQA_SO Results')\n",
        "plot_results(SEM_HyperIQA, 'SEM_HyperIQA_CO Results')"
      ],
      "metadata": {
        "id": "-JBI5YsehkU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "InW68dN8hkbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fIjouW6phkgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Model, kayıp fonksiyonu ve optimizer tanımlama\n",
        "model = SEM_HyperIQA_SO(patch_size=224, hyper_net_pretrained=None)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# CUDA veya CPU kullanımı\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Eğitim döngüsü\n",
        "def train_model(model, criterion, optimizer, train_loader, num_epochs=25):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs['quality'], labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "    print('Eğitim tamamlandı')\n",
        "    return model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFVJhEc3qwOi",
        "outputId": "4cd81e5e-655e-47fc-b626-e495d4e53603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 177MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sem_hyperiqa = SemHyperIQA(patchSize=224, hyperNetPretrained=None)\n",
        "full_hyperiqa = FullHyperIQA(patchSize=224, hyperNetPretrained=None)\n",
        "sem_hyperiqa_SO = SEM_HyperIQA_SO(patch_size=224, hyper_net_pretrained=None)\n",
        "\n",
        "\n",
        "sem_hyperiqa_SE_S = '/content/drive/MyDrive/SemHyperIQA_SE_D.pth'\n",
        "full_hyperiqa_SE_S = '/content/drive/MyDrive/FullHyperIQA_model_device.pth'\n",
        "sem_hyperiqa_SE_D = '/content/drive/MyDrive/saved_model3.pth'\n",
        "full_hyperiqa_SE_D = '/content/drive/MyDrive/FullHyperIQA_model_device.pth'\n",
        "\n",
        "sem_hyperiqa_SD_S = '/content/drive/MyDrive/SemHyperIQA_SD_S.pth'\n",
        "full_hyperiqa_SD_S = '/content/drive/MyDrive/FullHyperIQA_SD_S.pth'\n",
        "sem_hyperiqa_SD_D = '/content/drive/MyDrive/SemHyperIQA_SD_D.pth'\n",
        "full_hyperiqa_SD_D = '/content/drive/MyDrive/FullHyperIQA_SD_D.pth'\n",
        "\n",
        "sem_hyperiqa_SO_S = '/content/drive/MyDrive/SemHyperIQA_SO_S.pth'\n",
        "full_hyperiqa_SO_S = '/content/drive/MyDrive/FullHyperIQA_SO_S.pth'\n",
        "sem_hyperiqa_SO_D = '/content/drive/MyDrive/SemHyperIQA_SO_D.pth'\n",
        "full_hyperiqa_SO_D = '/content/drive/MyDrive/FullHyperIQA_SO_D.pth'\n",
        "\n",
        "sem_hyperiqa.load_state_dict(torch.load(sem_hyperiqa_SE_S))\n",
        "sem\n",
        "full_hyperiqa.load_state_dict(torch.load(full_hyperiqa_SE_S))\n",
        "sem_hyperiqa.load_state_dict(torch.load(sem_hyperiqa_SE_D))\n",
        "full_hyperiqa.load_state_dict(torch.load(full_hyperiqa_SE_D))\n",
        "\n",
        "\n",
        "sem_hyperiqa.eval()\n",
        "full_hyperiqa.eval()\n",
        "SEM_HyperIQA_SO.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "39y79DR17dvp",
        "outputId": "8c3c59a6-d569-4ee7-93d1-480bfd2fe176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "SEM_HyperIQA_CO.forward() got an unexpected keyword argument 'patch_size'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-89075368d158>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfull_hyperiqa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFullHyperIQA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatchSize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperNetPretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msem_hyperiqa_SO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSEM_HyperIQA_SO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_net_pretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mSEM_HyperIQA_CO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSEM_HyperIQA_CO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_net_pretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: SEM_HyperIQA_CO.forward() got an unexpected keyword argument 'patch_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import spearmanr, pearsonr, kendalltau\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "def calculate_metrics(predictions, targets):\n",
        "    srocc, _ = spearmanr(predictions, targets)\n",
        "    plcc, _ = pearsonr(predictions, targets)\n",
        "    krocc, _ = kendalltau(predictions, targets)\n",
        "    mea = mean_absolute_error(predictions, targets)\n",
        "    return srocc, plcc, krocc, mea"
      ],
      "metadata": {
        "id": "gA3uXye28DDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testDfPath = \"/content/drive/MyDrive/Dataset/device_split_test.csv\"\n",
        "testDf = pd.read_csv(testDfPath)\n",
        "\n",
        "transform = Compose([\n",
        "    Resize((224, 224)),\n",
        "    ToTensor(),\n",
        "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "test_dataset = CustomDataset(testDf, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "sem_hyperiqa_predictions = []\n",
        "full_hyperiqa_predictions = []\n",
        "sem_hyperiqa_SO_predictions = []\n",
        "sem_hyperiqa_CO_predictions = []\n",
        "true_values = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for images, labels in test_loader:\n",
        "    sem_hyperiqa_outputs = sem_hyperiqa(images)\n",
        "    full_hyperiqa_outputs = full_hyperiqa(images)\n",
        "\n",
        "    sem_hyperiqa_predictions.append(sem_hyperiqa_outputs['quality'].item())\n",
        "    full_hyperiqa_predictions.append(full_hyperiqa_outputs['quality'].item())\n",
        "    sem_hyperiqa_SO_predictions.append(SEM_HyperIQA_SO['quality'].item())\n",
        "    sem_hyperiqa_CO_predictions.append(SEM_HyperIQA_CO['quality'].item())\n",
        "    true_values.append(labels.item())"
      ],
      "metadata": {
        "id": "xKgkY5qr8GkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sem_hyperiqa_metrics = calculate_metrics(sem_hyperiqa_predictions, true_values)\n",
        "full_hyperiqa_metrics = calculate_metrics(full_hyperiqa_predictions, true_values)\n",
        "sem_hyperiqa_SO_metrics = calculate_metrics(sem_hyperiqa_SO_predictions, true_values)\n",
        "sem_hyperiqa_CO_metrics = calculate_metrics(sem_hyperiqa_CO_predictions, true_values)\n",
        "\n",
        "print(f\"SemHyperIQA Metrics: {sem_hyperiqa_metrics}\")\n",
        "print(f\"FullHyperIQA Metrics: {full_hyperiqa_metrics}\")\n",
        "print(f\"SEM_HyperIQA_SO Metrics: {sem_hyperiqa_SO_metrics}\")\n",
        "print(f\"SEM_HyperIQA_CO Metrics: {sem_hyperiqa_CO_metrics}\")"
      ],
      "metadata": {
        "id": "zIlcBxIp8Jfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    ('Details', 'SROCC'): [sem_hyperiqa_metrics[0], full_hyperiqa_metrics[0], sem_hyperiqa_SO_metrics[0], sem_hyperiqa_CO_metrics[0]],\n",
        "    ('Details', 'PLCC'): [sem_hyperiqa_metrics[1], full_hyperiqa_metrics[1], sem_hyperiqa_SO_metrics[1], sem_hyperiqa_CO_metrics[1]],\n",
        "    ('Details', 'KROCC'): [sem_hyperiqa_metrics[2], full_hyperiqa_metrics[2], sem_hyperiqa_SO_metrics[2], sem_hyperiqa_CO_metrics[2]],\n",
        "    ('Details', 'MAE'): [sem_hyperiqa_metrics[3], full_hyperiqa_metrics[3], sem_hyperiqa_SO_metrics[3], sem_hyperiqa_CO_metrics[3]],\n",
        "    ('Exposure', 'SROCC'): [sem_hyperiqa_metrics[0], full_hyperiqa_metrics[0], sem_hyperiqa_SO_metrics[0], sem_hyperiqa_CO_metrics[0]],  # Hypothetical, needs actual values\n",
        "    ('Exposure', 'PLCC'): [sem_hyperiqa_metrics[1], full_hyperiqa_metrics[1], sem_hyperiqa_SO_metrics[1], sem_hyperiqa_CO_metrics[1]],  # Hypothetical, needs actual values\n",
        "    ('Exposure', 'KROCC'): [sem_hyperiqa_metrics[2], full_hyperiqa_metrics[2], sem_hyperiqa_SO_metrics[2], sem_hyperiqa_CO_metrics[2]],  # Hypothetical, needs actual values\n",
        "    ('Exposure', 'MAE'): [sem_hyperiqa_metrics[3], full_hyperiqa_metrics[3], sem_hyperiqa_SO_metrics[3], sem_hyperiqa_CO_metrics[3]],  # Hypothetical, needs actual values\n",
        "    ('Overall', 'SROCC'): [sem_hyperiqa_metrics[0], full_hyperiqa_metrics[0], sem_hyperiqa_SO_metrics[0], sem_hyperiqa_CO_metrics[0]],  # Hypothetical, needs actual values\n",
        "    ('Overall', 'PLCC'): [sem_hyperiqa_metrics[1], full_hyperiqa_metrics[1], sem_hyperiqa_SO_metrics[1], sem_hyperiqa_CO_metrics[1]],  # Hypothetical, needs actual values\n",
        "    ('Overall', 'KROCC'): [sem_hyperiqa_metrics[2], full_hyperiqa_metrics[2], sem_hyperiqa_SO_metrics[2], sem_hyperiqa_CO_metrics[2]],  # Hypothetical, needs actual values\n",
        "    ('Overall', 'MAE'): [sem_hyperiqa_metrics[3], full_hyperiqa_metrics[3], sem_hyperiqa_SO_metrics[3], sem_hyperiqa_CO_metrics[3]],  # Hypothetical, needs actual values\n",
        "}\n",
        "\n",
        "# Çok katmanlı sütun başlıkları oluşturma\n",
        "columns = pd.MultiIndex.from_tuples([\n",
        "    ('Device Split', 'Details', 'SROCC'),\n",
        "    ('Device Split', 'Details', 'PLCC'),\n",
        "    ('Device Split', 'Details', 'KROCC'),\n",
        "    ('Device Split', 'Details', 'MAE'),\n",
        "    ('Device Split', 'Exposure', 'SROCC'),\n",
        "    ('Device Split', 'Exposure', 'PLCC'),\n",
        "    ('Device Split', 'Exposure', 'KROCC'),\n",
        "    ('Device Split', 'Exposure', 'MAE'),\n",
        "    ('Device Split', 'Overall', 'SROCC'),\n",
        "    ('Device Split', 'Overall', 'PLCC'),\n",
        "    ('Device Split', 'Overall', 'KROCC'),\n",
        "    ('Device Split', 'Overall', 'MAE')\n",
        "])\n",
        "\n",
        "# DataFrame'i çok katmanlı sütun başlıklarıyla oluşturma\n",
        "df = pd.DataFrame(data, index=['SemHyperIQA', 'FullHyperIQA', 'SEM_HyperIQA_SO', 'SEM_HyperIQA_CO'])\n",
        "df.columns = columns\n",
        "\n",
        "# İlk sütun olan Model\\Attribute'u ekleme\n",
        "df.index.name = 'Model\\\\Attribute'\n",
        "df.reset_index(inplace=True)\n",
        "\n",
        "# CSV dosyasına kaydetme\n",
        "df.to_csv('/content/drive/MyDrive/Device_Split_score.csv', index=False)\n",
        "print(f'Sonuçlar kaydedildi: /content/drive/MyDrive/Device_Split_score.csv')\n"
      ],
      "metadata": {
        "id": "Dbq3MFEn8MDF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPBBX/Cq8TzIzxNuJTW3Cin",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}